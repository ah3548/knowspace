-- phpMyAdmin SQL Dump
-- version 4.0.10deb1
-- http://www.phpmyadmin.net
--
-- Host: localhost
-- Generation Time: Apr 28, 2016 at 04:27 AM
-- Server version: 5.7.12
-- PHP Version: 5.5.9-1ubuntu4.14

SET SQL_MODE = "NO_AUTO_VALUE_ON_ZERO";
SET time_zone = "+00:00";


/*!40101 SET @OLD_CHARACTER_SET_CLIENT=@@CHARACTER_SET_CLIENT */;
/*!40101 SET @OLD_CHARACTER_SET_RESULTS=@@CHARACTER_SET_RESULTS */;
/*!40101 SET @OLD_COLLATION_CONNECTION=@@COLLATION_CONNECTION */;
/*!40101 SET NAMES utf8 */;

--
-- Database: `ks`
--

-- --------------------------------------------------------

--
-- Table structure for table `so_questions`
--

CREATE TABLE IF NOT EXISTS `so_questions` (
  `tags` varchar(255) CHARACTER SET utf8 DEFAULT NULL,
  `is_answered` varchar(4) CHARACTER SET utf8 DEFAULT NULL,
  `view_count` int(11) DEFAULT NULL,
  `answer_count` int(11) DEFAULT NULL,
  `score` int(11) DEFAULT NULL,
  `last_activity_date` int(11) DEFAULT NULL,
  `creation_date` int(11) DEFAULT NULL,
  `question_id` int(11) NOT NULL,
  `link` varchar(255) CHARACTER SET utf8 DEFAULT NULL,
  `title` varchar(255) CHARACTER SET utf8 DEFAULT NULL,
  `body` varchar(4000) CHARACTER SET utf8 DEFAULT NULL,
  `has_more` varchar(4) CHARACTER SET utf8 DEFAULT NULL,
  `quota_max` int(11) DEFAULT NULL,
  `quota_remaining` int(11) DEFAULT NULL,
  `createdAt` date NOT NULL,
  `updatedAt` date NOT NULL,
  PRIMARY KEY (`question_id`)
) ENGINE=InnoDB DEFAULT CHARSET=latin1;

--
-- Dumping data for table `so_questions`
--

INSERT INTO `so_questions` (`tags`, `is_answered`, `view_count`, `answer_count`, `score`, `last_activity_date`, `creation_date`, `question_id`, `link`, `title`, `body`, `has_more`, `quota_max`, `quota_remaining`, `createdAt`, `updatedAt`) VALUES
('["c++","math","matrix","linear-algebra"]', '1', 56797, 11, 143, 1459986839, 1252082758, 1380371, 'http://stackoverflow.com/questions/1380371/what-are-the-most-widely-used-c-vector-matrix-math-linear-algebra-libraries-a', 'What are the most widely used C++ vector/matrix math/linear algebra libraries, and their cost and benefit tradeoffs?', '<p>It seems that many projects slowly come upon a need to do matrix math, and fall into the trap of first building some vector classes and slowly adding in functionality until they get caught building a half-assed custom linear algebra library, and depending on it. </p>\n\n<p>I''d like to avoid that while not building in a dependence on some tangentially related library (e.g. OpenCV, OpenSceneGraph). </p>\n\n<p>What are the commonly used matrix math/linear algebra libraries out there, and why would decide to use one over another? Are there any that would be advised against using for some reason? I am specifically using this in a geometric/time context*(2,3,4 Dim)* but may be using higher dimensional data in the future. </p>\n\n<p>I''m looking for differences with respect to any of: API, speed, memory use, breadth/completeness, narrowness/specificness, extensibility, and/or maturity/stability.</p>\n\n<p><em>(Edit/note:  There''s a bit of information in the answers, but it''s scattered and without context. I''m unsure if I should pull it together in another answer, but I''m still not particularly clear on the benefits or downsides to any of these choices over another)</em></p>\n\n<p><em>I ended up using Eigen3 which I am extremely happy with</em></p>\n', NULL, NULL, NULL, '2016-04-28', '2016-04-28'),
('["matlab","math","computer-vision","linear-algebra","matlab-cvst"]', '1', 7449, 3, 10, 1458092314, 1265161124, 2189107, 'http://stackoverflow.com/questions/2189107/3d-correspondences-from-fundamental-matrix', '3D Correspondences from fundamental matrix', '<p>In MATLAB I have calculated the <a href="http://en.wikipedia.org/wiki/Fundamental_matrix_%28computer_vision%29">Fundamental matrix</a> (of two images) using the normalized <a href="http://en.wikipedia.org/wiki/Eight-point_algorithm">Eight point algorithm</a>. From that I need to <a href="http://en.wikipedia.org/wiki/Triangulation_%28computer_vision%29">triangulate</a> the corresponding image points in 3D space. From what I understand, to do this I would need the rotation and translation of the image''s cameras. The easiest way of course would be <a href="http://www.vision.caltech.edu/bouguetj/calib_doc/">calibrate the cameras</a> first then take the images, but this is too constricting for my application as it would require this extra step.</p>\n\n<p>So that leaves me with <a href="http://en.wikipedia.org/wiki/Camera_auto-calibration">auto (self) camera calibration</a>. I see mention of <a href="http://en.wikipedia.org/wiki/Bundle_adjustment">bundle adjustment</a>, however in <a href="http://books.google.com/books?id=jCsZ5rdwgqMC&amp;lpg=PP1&amp;ots=MjhMWP74VG&amp;dq=an%20invitation%20to%203d%20vision&amp;pg=PA167#v=onepage&amp;q=&amp;f=false">An Invitation to 3D Vision</a> it seems it requires an initial translation and rotation, which makes me think that a calibrated camera is needed or my understanding is falling short.</p>\n\n<p>So my question is how can I automatically extract the rotation/translation so I can reprojected/triangulate the image points into 3D space. Any MATLAB code or pseudocode would be fantastic.</p>\n', NULL, NULL, NULL, '2016-04-28', '2016-04-28'),
('["numpy","signal-processing","scipy","linear-algebra","convolution"]', '1', 2648, 2, 5, 1459430493, 1299562269, 5228718, 'http://stackoverflow.com/questions/5228718/convolution-along-one-axis-only', 'Convolution along one axis only', '<p>I have two 2-D arrays with the same first axis dimensions. In python, I would like to convolve the two matrices along the second axis only. I would like to get <code>C</code> below without computing the convolution along the first axis as well.</p>\n\n<pre><code>import numpy as np\nimport scipy.signal as sg\n\nM, N, P = 4, 10, 20\nA = np.random.randn(M, N)\nB = np.random.randn(M, P)\n\nC = sg.convolve(A, B, ''full'')[(2*M-1)/2]\n</code></pre>\n\n<p>Is there a fast way?</p>\n', NULL, NULL, NULL, '2016-04-28', '2016-04-28'),
('["matlab","linear-algebra"]', '1', 1705, 5, 5, 1457539490, 1308060319, 6344800, 'http://stackoverflow.com/questions/6344800/solving-multiple-linear-systems-using-vectorization', 'Solving multiple linear systems using vectorization', '<p>Sorry if this is obvious but I searched a while and did not find anything (or missed it).</p>\n\n<p>I''m trying to solve linear systems of the form <em>Ax=B</em> with <em>A</em> a 4x4 matrix, and <em>B</em> a 4x1 vector.</p>\n\n<p>I know that for a single system I can use <code>mldivide</code> to obtain <em>x</em>: <code>x=A\\B</code>.</p>\n\n<p>However I am trying to solve a great number of systems (possibly > 10000) and I am reluctant to use a for loop because I was told it is notably slower than matrix formulation in many MATLAB problems.</p>\n\n<p>My question is then: is there a way to solve <em>Ax=B</em> using vectorization with <em>A</em> 4x4x <em>N</em> and <em>B</em> a matrix 4x <em>N</em> ?</p>\n\n<p>PS: I do not know if it is important but the <em>B</em> vector is the same for all the systems.</p>\n', NULL, NULL, NULL, '2016-04-28', '2016-04-28'),
('["c++","opencv","computer-vision","linear-algebra"]', '1', 2956, 2, 2, 1458439794, 1335800307, 10386382, 'http://stackoverflow.com/questions/10386382/use-fundamental-matrix-to-compute-coordinates-translation-using-opencv', 'Use fundamental matrix to compute coordinates translation using OpenCV', '<p>I am trying to compute the coordinates correspondence of several points between two images.\nI have a group of points whose correspondences are known, I use them with OpenCV''s <code>findFundamentalMatrix()</code> in order to find the fundamental matrix.\nI verified that <code>x^T * F * x'' = (0)</code> for each point, and the result is always right or very close.</p>\n\n<p>The thing is, now I''d like to use the coordinates of a point on the first image (<code>y</code>) and the fundamental matrix (<code>F</code>) in order to find the coordinates of the point on the second image (<code>y''</code>). I first thought about simply using the equation above, but given only the <code>z</code> of the <code>y''</code> point, there can be <a href="http://math.stackexchange.com/questions/136888/matrix-equation" title="Matrix equation on math.stackexchange">an infinity of solutions</a>.</p>\n\n<p>How else can I use the fundamental matrix to compute the translations ?</p>\n\n<p>To be more clear: knowing the fundamental matrix "linking" two projections, how can I use it to translate the coordinates of any known point <code>(a, b, 1)</code> from the first projection to the second projection?</p>\n\n<p>Considering that we know <code>a</code>, <code>b</code> and <code>F</code> in this equation: (a'', b", 1)<sup>T</sup> * F * (a, b, 1) = (0)</p>\n\n<p>I had made a simple drawing as an example: <a href="http://i.imgur.com/drNr2.jpg" rel="nofollow">http://i.imgur.com/drNr2.jpg</a> . The idea is to find the coordinates of the red dot <code>(xq, yq)</code> in projection 2, considering that we know its coordinates in projection 1 and the ones of all other points in both projections (and some other ones as the algorithm to find the fundamental matrix actually requires at least 8 points)</p>\n\n<p>Another precision: in my example, known points are coplanar, but the researched point will not necessarily be.</p>\n\n<p>I hope that made my problem more clear :)</p>\n', NULL, NULL, NULL, '2016-04-28', '2016-04-28'),
('["ios","core-graphics","linear-algebra"]', '1', 1424, 4, 7, 1460339505, 1337778383, 10720569, 'http://stackoverflow.com/questions/10720569/is-there-a-way-to-calculate-the-cgaffinetransform-needed-to-transform-a-view-fro', 'Is there a way to calculate the CGAffineTransform needed to transform a view from frame A to frame B?', '<p>Say, I have two CGRects, CGRect A and CGRect B. My UIView''s frame is the same as CGRect B, but I want to create an animation showing the UIView transitioning from frame A to B.</p>\n\n<p>I''m trying to do this by changing the transform property of the UIView, so I don''t have to mess around with its frame too much. However, I need the CGAffineTransform to make this possible. What is the best way to calculate this transform?</p>\n', NULL, NULL, NULL, '2016-04-28', '2016-04-28'),
('["arrays","arraylist","drawing","processing","linear-algebra"]', '1', 652, 2, 0, 1457370134, 1349363033, 12730225, 'http://stackoverflow.com/questions/12730225/how-to-realize-the-drawing-processing-in-processing', 'How to realize the DRAWING processing in Processing?', '<p>We all know how to draw a line in Processing. </p>\n\n<p>But when we draw a line, the line is shown immediately.</p>\n\n<p>What if i want to witness the drawing process, namely, to see the line moving forward, gradually completes a whole line.</p>\n\n<p>Here''s what i want to realize: to DRAW several lines and curves which finally turn into some pattern.</p>\n\n<p>So how to make that happen? Using array?</p>\n\n<p>Many thanks.</p>\n', NULL, NULL, NULL, '2016-04-28', '2016-04-28'),
('["opengl","linear-algebra","glulookat"]', '1', 240, 2, 0, 1461607327, 1374300522, 17759269, 'http://stackoverflow.com/questions/17759269/please-can-you-explain-my-glulookat-misconception', 'Please can you explain my gluLookAt() misconception?', '<p>I have learned from reading many sources and by re-implementing the function and studying the matrices myself, that gluLookAt() is equivalent to a rotation followed by a translation to the inverse eye coordinate. The implementation is similar in OpenGL, MESA, Cogl etc... and a good summary is here:\n<a href="http://pic.dhe.ibm.com/infocenter/aix/v7r1/topic/com.ibm.aix.opengl/doc/openglrf/gluLookAt.htm" rel="nofollow">http://pic.dhe.ibm.com/infocenter/aix/v7r1/topic/com.ibm.aix.opengl/doc/openglrf/gluLookAt.htm</a></p>\n\n<p>However, consider the case where the look-at target is at the origin i.e. (0, 0, 0), and the virtual camera is slightly offset from the Z-axis e.g. (2, 2, 10). The outcome of gluLookAt() should have the origin in the center of the field of view. The initial rotation step is of no consequence, but the later translation step moves the origin away from the center!</p>\n\n<p>Can you explain my gluLookAt() misconception?</p>\n', NULL, NULL, NULL, '2016-04-28', '2016-04-28'),
('["javascript","svg","linear-algebra","bezier-curve"]', '1', 1383, 3, 3, 1459959548, 1378461856, 18655135, 'http://stackoverflow.com/questions/18655135/divide-bezier-curve-into-two-equal-halves', 'Divide bezier curve into two equal halves', '<p>I have the bezier curves between 2 points. I''d like to cut all curves into two equal half.\nOne of my idea is if I can control ''t'' value I''ll draw 2 curves by t = [0,0.5] and t = [0.5,1] but I don''t know how. Below is my code. I won''t mind any other idea or suggestion</p>\n\n<pre><code>&lt;!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"&gt;\n&lt;html xmlns="http://www.w3.org/1999/xhtml"&gt;\n&lt;head&gt;\n    &lt;meta http-equiv="Content-Type" content="text/html; charset=utf-8" /&gt;\n    &lt;title&gt;D3 test&lt;/title&gt;\n    &lt;script src="http://d3js.org/d3.v3.min.js"&gt;&lt;/script&gt;\n\n    &lt;script&gt;\n    var Over = function(){\n        d3.select(this)\n        .style("stroke-opacity", 0.25);\n    }\n    var Out = function(){\n        d3.select(this)\n        .transition().duration(200)\n        .style("stroke-opacity", 0);\n    }\n\n    function curve(n,x1,y1,x2,y2){\n\n        var xr = (x1+x2)/2,\n            yr = (y1+y2)/2,\n            euDist = Math.sqrt(Math.pow(x2-x1,2)+Math.pow(y2-y1,2)),\n            x3 = -y1+xr+yr, x4 = -y2+xr+yr,\n            y3 =  x1+yr-xr, y4 =  x2+yr-xr,\n            ctrl , curveDescription;\n\n        svg.append(''path'')\n            .attr("stroke", ''blue'')\n            .attr(''fill'',''none'')\n            .style("stroke-opacity",0.25)\n            .attr(''d'', ''M''+x3+'',''+y3+''L''+x4+'',''+y4)\n            .attr(''stroke-width'',strokeWidth);\n\n        for(var j=0;j&lt;=n;j++){\n            ctrl = [(x4-x3)*j/n+x3 , (y4-y3)*j/n+y3] ,                  \n            curveDescription=   \n                    ''M'' +x1+'',''     +y1+ \n                    ''Q'' +ctrl[0]+'',''+ctrl[1]+'',''\n                        +x2+'',''     +y2;\n\n            svg.append(''path'')\n                .attr("stroke", ''blue'')\n                .attr(''fill'',''none'')\n                .style("stroke-opacity",0.25)\n                .attr(''d'', curveDescription)\n                .attr(''stroke-width'',strokeWidth);  \n\n            svg.append(''path'')\n                .attr("stroke", ''blue'')\n                .attr(''fill'',''none'')\n                .style("stroke-opacity",0)\n                .on("mouseover", Over)\n                .on("mouseout", Out)\n                .attr(''d'', curveDescription)\n                .attr(''stroke-width'',strokeWidth*25);\n\n        }\n\n    }\n    &lt;/script&gt;\n\n&lt;/head&gt;\n\n&lt;body&gt;\n    &lt;script&gt;\n    var w = 1268 , h = 680 , strokeWidth = 2;\n\n    var svg = d3.select("body")\n                .append("svg")\n                .attr("width", w)\n                .attr("height", h)\n\n    curve(5, 100,100, 400,500);\n\n\n    &lt;/script&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n</code></pre>\n', NULL, NULL, NULL, '2016-04-28', '2016-04-28'),
('["python","performance","numpy","linear-algebra","blas"]', '1', 6415, 2, 16, 1459148189, 1392016331, 21671040, 'http://stackoverflow.com/questions/21671040/link-atlas-mkl-to-an-installed-numpy', 'Link ATLAS/MKL to an installed Numpy', '<p><strong>TL;DR</strong> how to link ATLAS/MKL to existing Numpy without rebuilding.</p>\n\n<p>I have used Numpy to calculate with the large matrix and I found that it is very slow because Numpy only use 1 core to do calculation. After doing a lot of search I figure that my Numpy does not link to some optimized library like ATLAS/MKL. Here is my config of numpy:</p>\n\n<pre><code>&gt;&gt;&gt;import numpy as np\n&gt;&gt;&gt;np.__config__.show()\nblas_info:\n    libraries = [''blas'']\n    library_dirs = [''/usr/lib'']\n    language = f77\nlapack_info:\n    libraries = [''lapack'']\n    library_dirs = [''/usr/lib'']\n    language = f77\natlas_threads_info:\n    NOT AVAILABLE\nblas_opt_info:\n    libraries = [''blas'']\n    library_dirs = [''/usr/lib'']\n    language = f77\n    define_macros = [(''NO_ATLAS_INFO'', 1)]\natlas_blas_threads_info:\n  NOT AVAILABLE\nopenblas_info:\n  NOT AVAILABLE\nlapack_opt_info:\n    libraries = [''lapack'', ''blas'']\n    library_dirs = [''/usr/lib'']\n    language = f77\n    define_macros = [(''NO_ATLAS_INFO'', 1)]\natlas_info:\n  NOT AVAILABLE\nlapack_mkl_info:\n  NOT AVAILABLE\nblas_mkl_info:\n  NOT AVAILABLE\natlas_blas_info:\n  NOT AVAILABLE\nmkl_info:\n  NOT AVAILABLE\n</code></pre>\n\n<p>For this reason, I want to link ATLAS/MKL to Numpy. However, my Numpy is installed from PIP so I don''t want to install manually because I want to use the latest version. I have done some search but they are only for building from scratch. For this reason, my question are:</p>\n\n<ul>\n<li>Are there any way to link ATLAS/MKL to Numpy without rebuilding again?</li>\n<li>I have found that the config info is saved in <strong>_<em>config</em>_.py</strong> in the installed folder of Numpy. So will modifying it solve my problem? If yes, would you please show me how?</li>\n</ul>\n', NULL, NULL, NULL, '2016-04-28', '2016-04-28'),
('["numpy","scipy","linear-algebra","eigenvalue"]', '0', 218, 2, 2, 1459486682, 1402715725, 24216273, 'http://stackoverflow.com/questions/24216273/error-when-computing-eigenvalues-of-a-scipy-linearoperator-gmres-did-not-conve', 'Error when computing eigenvalues of a scipy LinearOperator: &quot;gmres did not converge&quot;', '<p>I''m trying to solve a large eigenvalue problem with Scipy where the matrix <code>A</code> is dense but I can compute its action on a vector without having to assemble <code>A</code> explicitly. So in order to avoid memory issues when the matrix A gets big I''d like to use the sparse solver <code>scipy.sparse.linalg.eigs</code> with a <code>LinearOperator</code> that implemements this action.</p>\n\n<p>Applying <code>eigs</code> to an explicit numpy array <code>A</code> works fine. However, if I apply <code>eigs</code> to a <code>LinearOperator</code> instead then the iterative solver fails to converge. This is true even if the <code>matvec</code> method of the <code>LinearOperator</code> is simply matrix-vector multiplication with the given matrix <code>A</code>.</p>\n\n<p>A minimal example illustrating the failure is attached below (I''m using shift-invert mode because I am interested in the smallest few eigenvalues). This computes the eigenvalues of a random matrix <code>A</code> just fine, but fails when applied to a <code>LinearOperator</code> that is directly converted from <code>A</code>. I tried to fiddle with the parameters for the iterative solver (<code>v0</code>, <code>ncv</code>, <code>maxiter</code>) but to no avail.</p>\n\n<p>Am I missing something obvious? Is there a way to make this work? Any suggestions would be highly appreciated. Many thanks!</p>\n\n<p><strong>Edit:</strong> I should clarify what I mean by "make this work" (thanks, Dietrich). The example below uses a random matrix for illustration. However, in my application I know that the eigenvalues are almost purely imaginary (or almost purely real if I multiply the matrix by <code>1j</code>). I''m interested in the 10-20 smallest-magnitude eigenvalues, but the algorithm doesn''t behave well (i.e., never stops even for small-ish matrix sizes) if I specify <code>which=''SM''</code>. Therefore I''m using shift-invert mode by passing the parameters <code>sigma=0.0, which=''LM''</code>. I''m happy to try a different approach so long as it allows me to compute a bunch of smallest-magnitude eigenvalues. </p>\n\n<pre><code>from scipy.sparse.linalg import eigs, LinearOperator, aslinearoperator\nimport numpy as np\n\n# Set a seed for reproducibility\nnp.random.seed(0)\n\n# Size of the matrix\nN = 100\n\n# Generate a random matrix of size N x N\n# and compute its eigenvalues\nA = np.random.random_sample((N, N))\neigvals = eigs(A, sigma=0.0, which=''LM'', return_eigenvectors=False)\nprint eigvals\n\n# Convert the matrix to a LinearOperator\nA_op = aslinearoperator(A)\n\n# Try to solve the same eigenproblem again.\n# This time it produces an error:\n#\n# ValueError: Error in inverting M: function gmres did not converge (info = 1000).\neigvals2 = eigs(A_op, sigma=0.0, which=''LM'', return_eigenvectors=False)\n</code></pre>\n', NULL, NULL, NULL, '2016-04-28', '2016-04-28'),
('["matlab","linear-algebra","solver","differential-equations"]', '0', 152, 0, 0, 1460886591, 1417538728, 27254594, 'http://stackoverflow.com/questions/27254594/fast-linear-system-solver-for-large-systems', 'Fast linear system solver for large systems', '<p>How do I solve a large linear system where the system matrix is banded diagonal? Just using <code>\\</code> takes longer than I would like. I am open to use iterative methods, if this is the only alternative, but is there any known efficient m-files already implemented? What should I look for?\nThanks a lot! </p>\n', NULL, NULL, NULL, '2016-04-28', '2016-04-28'),
('["linear-algebra","intel-mkl"]', '0', 45, 1, 0, 1457415749, 1427228450, 29242129, 'http://stackoverflow.com/questions/29242129/using-the-three-array-bsr-format-in-mkl-for-rectangular-matrix-vector-products', 'Using the three array BSR format in MKL for rectangular matrix vector products', '<p>MKL is the intel math kernel library used for fast linear algebra on CPUs. BSR is the block sparse row format for sparse matrices. I need to compute a matrix vector product of a block sparse matrix using the 3 array BSR representation of a sparse rectangular matrix. The functions that exist for the 3-array version only takes square matrices. The function that can take rectangular matrices requires the 4 array version of the BSR format. mkl_?bsrgemv is the version that uses the 3-array version and mkl_?bsrmv is the function that can use take rectangular matrices but requires the 4-array version. Is anyone aware if it is possible to complete the operation on a rectangular matrix without resorting to padding on the input or output vectors? I checked the documentation for any clues but I may have missed something.</p>\n', NULL, NULL, NULL, '2016-04-28', '2016-04-28'),
('["python","scipy","linear-algebra","preconditions"]', '1', 197, 1, 2, 1458833048, 1443615371, 32865832, 'http://stackoverflow.com/questions/32865832/preconditioned-conjugate-gradient-and-linearoperator-in-python', 'Preconditioned Conjugate Gradient and LinearOperator in python', '<p>[Homework] I am going to solve the linear system Ax=b by the Preconditioned Conjugate Gradient method, and I use spilu function from scipy.sparse.linalg for the preconditioner. A is a sparse symmetric 162*162 matrix. Since the spilu gives an approximation to the inverse of A, say M approximates A, and so spilu(A) gives M^-1, which is the preconditioner. I find that we can directly gives the preconditioner in the python Conjugate Gradient function, but my code below does not work.</p>\n\n<pre><code>M_inverse=scipy.sparse.linalg.spilu(A)\nM2=scipy.sparse.linalg.LinearOperator((162,162),M_inverse.solve)\nx3=scipy.sparse.linalg.cg(A,b,M2)\nTypeError                                 Traceback (most recent call last)\n&lt;ipython-input-84-86f8f91df8d2&gt; in &lt;module&gt;()\n----&gt; 1 x3=scipy.sparse.linalg.cg(A,b,M2)\n\n/Users/ruobinghan/anaconda/lib/python3.4/site-packages/scipy/sparse/linalg/isolve/iterative.py in cg(A, b, x0, tol, maxiter, xtype, M, callback)\n\n/Users/ruobinghan/anaconda/lib/python3.4/site-packages/scipy/sparse/linalg/isolve/iterative.py in non_reentrant(func, *a, **kw)\n     83     try:\n     84         d[''__entered''] = True\n---&gt; 85         return func(*a, **kw)\n     86     finally:\n     87         d[''__entered''] = False\n\n/Users/ruobinghan/anaconda/lib/python3.4/site-packages/scipy/sparse/linalg/isolve/iterative.py in cg(A, b, x0, tol, maxiter, xtype, M, callback)\n    219 @non_reentrant\n    220 def cg(A, b, x0=None, tol=1e-5, maxiter=None, xtype=None, M=None, callback=None):\n--&gt; 221     A,M,x,b,postprocess = make_system(A,M,x0,b,xtype)\n    222 \n    223     n = len(b)\n\n/Users/ruobinghan/anaconda/lib/python3.4/site-packages/scipy/sparse/linalg/isolve/utils.py in make_system(A, M, x0, b, xtype)\n    108         x = zeros(N, dtype=xtype)\n    109     else:\n--&gt; 110         x = array(x0, dtype=xtype)\n    111         if not (x.shape == (N,1) or x.shape == (N,)):\n    112             raise ValueError(''A and x have incompatible dimensions'')\n\nTypeError: float() argument must be a string or a number, not ''LinearOperator'' \n</code></pre>\n\n<p>Also, the question hints I will need to use LinearOperator interface, I do not understand what is exactly LinearOperator doing and why we need it here.</p>\n\n<p>Any suggestion would be appreciated!\nThanks in advance!</p>\n', NULL, NULL, NULL, '2016-04-28', '2016-04-28'),
('["matrix","linear-algebra","sympy"]', '1', 34, 1, 0, 1458759892, 1445714421, 33322317, 'http://stackoverflow.com/questions/33322317/finding-an-answer-to-a-singular-matrix-equation-if-it-exists-in-sympy', 'Finding an answer to a singular matrix equation if it exists in SymPy', '<p>Suppose we have the matrix equation <code>A*x = b</code> where <code>A</code> is square but singular. Then in general the equation either has no solutions or infinitely many solutions. If it does have solutions, I''d like to find their form <em>symbolically</em> in terms of free variables using SymPy. </p>\n\n<p>I know if we can find one specific solution <code>x</code>, then by adding vectors from the nullspace of <code>A</code> onto <code>x</code> we may find the rest, so the problem is reduced to finding just one solution. In Mathematica the function <code>LinearSolve</code> will give you such a solution, but unfortunately in SymPy all of the solvers seem to require that A be non-singular.</p>\n\n<p>Does anyone know how I might find such a solution (<em>symbolically</em>) using SymPy? I''ve been looking into rolling my own algorithm to do this, possibly by using <code>A.rref()</code> to put <code>A</code> into reduced row echelon format first, but I''m not confident enough in my linear algebra to know if this would work stably. Another possibility might be calculating the pseudoinverse, but the function <code>pinv()</code> complains about singular matrices.</p>\n', NULL, NULL, NULL, '2016-04-28', '2016-04-28'),
('["python","numpy","linear-algebra","matrix-multiplication","numpy-broadcasting"]', '1', 137, 4, 2, 1458234559, 1448797184, 33982359, 'http://stackoverflow.com/questions/33982359/why-does-numpy-dot-behave-in-this-way', 'Why does numpy.dot behave in this way?', '<p>I''m trying to understand why numpy''s <code>dot</code> function behaves as it does:</p>\n\n<pre><code>M = np.ones((9, 9))\nV1 = np.ones((9,))\nV2 = np.ones((9, 5))\nV3 = np.ones((2, 9, 5))\nV4 = np.ones((3, 2, 9, 5))\n</code></pre>\n\n<p>Now <code>np.dot(M, V1)</code> and <code>np.dot(M, V2)</code> behave as\nexpected. But for <code>V3</code> and <code>V4</code> the result surprises\nme:</p>\n\n<pre><code>&gt;&gt;&gt; np.dot(M, V3).shape\n(9, 2, 5)\n&gt;&gt;&gt; np.dot(M, V4).shape\n(9, 3, 2, 5)\n</code></pre>\n\n<p>I expected <code>(2, 9, 5)</code> and <code>(3, 2, 9, 5)</code> respectively. On the other hand, <code>np.matmul</code>\ndoes what I expect: the matrix multiply is broadcast\nover the first <em>N - 2</em> dimensions of the second argument and\nthe result has the same shape:</p>\n\n<pre><code>&gt;&gt;&gt; np.matmul(M, V3).shape\n(2, 9, 5)\n&gt;&gt;&gt; np.matmul(M, V4).shape\n(3, 2, 9, 5)\n</code></pre>\n\n<p>So my question is this: what is the rationale for\n<code>np.dot</code> behaving as it does? Does it serve some particular purpose,\nor is it the result of applying some general rule?</p>\n', NULL, NULL, NULL, '2016-04-28', '2016-04-28'),
('["apache-spark","linear-algebra","svd","apache-spark-mllib"]', '0', 128, 0, 2, 1461583074, 1453987034, 35062600, 'http://stackoverflow.com/questions/35062600/native-library-missing-warning-while-running-svd-on-10kx10k-dense-matrix', 'Native library missing warning while running SVD on 10Kx10K dense matrix', '<p>I am doing SVD on a dense matrix of size 10000x10000 using computeSVD method on IndexedRowMatrix on Apche Spark. The run log shows warning as follows</p>\n\n<pre><code>WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS\n\nWARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS\n\nWARN LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeSystemLAPACK\n\nWARN LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeRefLAPACK\n</code></pre>\n\n<p>Kindly let me know if that affects the running time of my spark job and if yes how to install them on CentOS.</p>\n\n<p>Thanks in Advance...</p>\n', NULL, NULL, NULL, '2016-04-28', '2016-04-28'),
('["linear-algebra","sparse-matrix","numerical-methods"]', '0', 55, 1, 0, 1459495950, 1454906196, 35262413, 'http://stackoverflow.com/questions/35262413/linear-iterative-solver-vs-direct-solver-stability', 'Linear iterative solver vs direct solver stability', '<p>Is iterative solver more stable than direct solver based on LU factorization. For LU based solver, we always have cond(A) &lt; cond(L) * cond(U), so factorization amplifies numerical inaccuracy. So in the event of an ill conditioned matrix A, whose condition number is large than 1e10, will it be better off using iterative solver for stability and numerical accuracy?</p>\n', NULL, NULL, NULL, '2016-04-28', '2016-04-28'),
('["matlab","plot","linear-algebra"]', '0', 39, 2, 0, 1457945487, 1456077684, 35539798, 'http://stackoverflow.com/questions/35539798/plotting-vectors-with-same-length', 'Plotting vectors with same length', '<pre><code>function SS(A,b,x)\n\nsum = A*x+b;\n\nxaxis=linspace(-10,10);\nylabel(''y'')\nxlabel(''x'')\n\nsubplot(1,2,1)\nplot(xaxis,sum)\naxis([0 1 0 1])\n\nsubplot(1,2,2)\nplot(xaxis,x)\n</code></pre>\n\n<p>I get the error:</p>\n\n<blockquote>\n  <p>Error using plot Vectors must be the same length.</p>\n  \n  <p>Error in SS (line 12)</p>\n  \n  <p>plot(xaxis,sum)</p>\n</blockquote>\n\n<p>I gave the A matrix a 2x2 and vectors b &amp; x an random 2x1 vector. The way I see, it''s the same length.</p>\n', NULL, NULL, NULL, '2016-04-28', '2016-04-28'),
('["java","math","linear-algebra","nonlinear-functions","apache-commons-math"]', '1', 98, 2, 2, 1458028603, 1456753572, 35701194, 'http://stackoverflow.com/questions/35701194/how-to-solve-this-set-of-nonlinear-trigonometric-equations-in-java', 'How to solve this set of nonlinear trigonometric equations in Java?', '<p>I am trying to solve a system of trigonometric equations in <code>Java</code>, but I don''t know where to start. I''ve used <code>commons-math3</code> before to solve simple linear sets of equations, but this is above my head. Equations I am trying to solve:</p>\n\n<ul>\n<li><p>a - e + b<em>cosθ<sub>1</sub> + c</em>sinθ<sub>1</sub> + d*sin(θ<sub>2</sub>+θ<sub>1</sub>)= z </p></li>\n<li><p>( b<em>sinθ<sub>1</sub> + c</em>cosθ<sub>1</sub> + d*cos(θ<sub>2</sub>-θ<sub>1</sub>) * sinθ<sub>0</sub> = x</p></li>\n<li><p>( b<em>sinθ<sub>1</sub> + c</em>cosθ<sub>1</sub> + d*cos(θ<sub>2</sub>-θ<sub>1</sub>) * sinθ<sub>0</sub> = y</p></li>\n</ul>\n\n<p>, where a,b,c,d and e are constants. In practical terms, given x, y, and z, I need to solve for θ<sub>0</sub>, θ<sub>1</sub>, θ<sub>2</sub>.</p>\n', NULL, NULL, NULL, '2016-04-28', '2016-04-28'),
('["linear-algebra","lapack","cusolver","qr-decomposition"]', '0', 26, 1, 0, 1457377900, 1457256872, 35825278, 'http://stackoverflow.com/questions/35825278/lapack-orthonormalization-function-for-rectangular-matrix', 'Lapack Orthonormalization Function for Rectangular Matrix', '<p>I was wondering if there was a function in Lapack for orthonormalizing the columns of a very tall and skinny matrix. <a href="http://stackoverflow.com/questions/4515103/lapack-orthonormalization-function">A similar previous question asked this question, presumably in the context of a square matrix</a>. My setting is as follows: I have an M by N matrix A that I am trying to orthonormalize the columns of.</p>\n\n<p>So, my first thought was to do a qr decomposition. The functions for doing a qr decomposition in Lapack seem to be dgeqrf and dormqr. Great. However, my problem is as follows: my matrix A is so tall, that I don''t want to actually compute all of Q, because it is M by M. In fact, I can''t afford to instantiate an M by M matrix at all during any of my computation (it would not fit in memory). I would rather compute just the matrix that <a href="https://en.wikipedia.org/wiki/QR_decomposition#Rectangular_matrix" rel="nofollow">wikipedia calls Q1</a>. However, I can''t seem to find a way to make this work.</p>\n\n<p>The weird thing is, that I think it is possible. Numpy, in particular, has a function <a href="https://github.com/numpy/numpy/blob/v1.10.0/numpy/linalg/linalg.py#L617-L826" rel="nofollow">numpy.linalg.qr</a> that appears to do just this. However, even after reading their source code, I can''t figure out how they are using lapack calls to get this to work.</p>\n\n<p>Do folks have ideas? I would strongly prefer this to only use lapack functions because I am hoping to port this code to CuSOLVE, which has implemented several lapack functions (including dgeqrf and dormqr) for the GPU.</p>\n', NULL, NULL, NULL, '2016-04-28', '2016-04-28'),
('["r","matrix","linear-algebra","rcpp","armadillo"]', '1', 83, 1, 2, 1457281000, 1457280402, 35829153, 'http://stackoverflow.com/questions/35829153/is-there-a-faster-way-to-do-this-cholesky-factorization-in-rcpp-c', 'Is there a faster way to do this Cholesky factorization in Rcpp/c++?', '<p>This is a problem arose in my Markov Chain Monte Carlo (MCMC) algorithm. And I feel this problem is quite commonly encountered especially in hierarchical Gaussian models. Hence it would be great if there is a much more efficient solution. So the problem is like this:</p>\n\n<p>I have many positive integer vectors <code>xi</code>, for <code>i</code> from 1 to n, a p.s.d. matrix <code>A</code> and a p.s.d. matrix <code>B</code>. For every <code>xi</code> I want to compute the following Cholesky factorization:</p>\n\n<blockquote>\n  <p>chol( kron( diagmat( xi ), A ) + B )</p>\n</blockquote>\n\n<p>So <code>kron( diagmat( xi ), A ) + B</code> is the covariance matrix for a multivariate Gaussian and I want to sample from this Gaussian hence need the Cholesky factorization of it. The dimension for <code>A</code> and <code>B</code> are not small and I have a large <code>n</code> hence computing the above Cholesky factorization for all <code>xi</code> is really time-consuming. Below is the <code>Rcpp</code> function I wrote using <code>RcppArmadillo</code>:</p>\n\n<pre><code>#include &lt;cmath&gt;\n#include &lt;Rmath.h&gt;\n#include "RcppArmadillo.h"\n// [[Rcpp::depends(RcppArmadillo)]]\nusing namespace arma;\nusing namespace Rcpp;\n\n// [[Rcpp::export]]\nmat test_C(mat A, mat B, mat X){\n  int n_x = X.n_cols;\n  int d_B = B.n_rows;\n  mat sample(d_B, n_x);\n  mat mS_chol_inv;\n  for (int i = 0; i &lt; n_x; i++){\n    mS_chol_inv = inv(trimatu( chol(kron(diagmat( X.col(i) ),A) + B) ));\n    sample.col(i) = mS_chol_inv*randn(d_B);\n  }\n  return(sample);\n}\n</code></pre>\n\n<p>I also test the computational efficiency using the following code comparing it to its R counterpart:</p>\n\n<pre><code>test_R &lt;- function(A,B,X){\n  n_x &lt;- ncol(X)\n  d_B &lt;- ncol(B)\n  res &lt;- sapply(1:n_x, function(x){\n    mS_chol &lt;- chol( kronecker( diag(X[,x]),A ) + B )\n    return( mS_chol%*%as.matrix( rnorm(d_B) ) )\n  })\n  return(res)\n}\n\n# Simulate Data\nR1 &lt;- matrix(rnorm(24*2),24,2)\nA &lt;- R1%*%t(R1) + 0.1*diag(24)\nR2 &lt;- matrix(rnorm(264*2),264,2)\nB &lt;- R2%*%t(R2) + 0.1*diag(264)\nX &lt;- matrix(rpois(11*2178, 5),11,2178)\n\nres &lt;- benchmark(res_R &lt;- test_R(A, B, X),\n             res_C &lt;- test_C(A, B, X),\n             columns=c("test", "replications", "elapsed", "relative"),\n             order="relative",\n             replications = 2)\n</code></pre>\n\n<p>And the result is as follows</p>\n\n<pre><code>&gt; print(res) \n                      test replications elapsed relative\n1 res_R &lt;- test_R(A, B, X)            2  18.920    1.000\n2 res_C &lt;- test_C(A, B, X)            2  20.724    1.095\n</code></pre>\n\n<p>As can be seen, a single run is approximately 10 second, and this is simply not feasible in a MCMC algorithm. Also, since the <code>chol()</code> dominates the computational complexity, the improvement of using <code>Rcpp</code> over pure <code>R</code> is trivial. But maybe I did not write the most efficient code? So any advice?</p>\n\n<p>Since the matrix inside <code>chol()</code> is very structured and the only thing that is varying is <code>xi</code>, maybe there is some algebra trick that I do not know that can solve this efficiently? I have posted this as a linear-algebra question under <strong>Mathematics</strong> and here is the <a href="http://math.stackexchange.com/questions/1684978/faster-cholesky-factorization-of-diag-mathbfx-i-otimes-mathbfa-mat">link</a>. Unfortunately so far I have not received any solution, people do point out that this is embarrassingly parallel.</p>\n\n<p>Any advice on code/algebra will be helpful! Thanks ahead for your time.</p>\n', NULL, NULL, NULL, '2016-04-28', '2016-04-28'),
('["linear-algebra","edge-detection","supervised-learning","patching"]', '0', 22, 0, 0, 1457282605, 1457282605, 35829547, 'http://stackoverflow.com/questions/35829547/overcompleteness-edge-detection-patching', 'Overcompleteness edge detection / patching', '<p>I am having troubles understanding the definitions of over completeness: In an overcomplete basis, the number of basis vectors is greater than the dimensionality of the input, and the representation of an input is not a unique combination of basis vectors.</p>\n\n<p>So lets say we have basis vectors: [(0,0,1,1),(0,1,1,0),(1,1,0,0)]</p>\n\n<p>So the number of basis vectors totals to 3.</p>\n\n<p>This means that the input dimension must be &lt; 3?</p>\n\n<p>My main goal is to see how this relates to image patching with sparse overcomplete code.</p>\n\n<p>Here is the thesis that I am attempting to digest: <a href="http://ttic.uchicago.edu/~gregory/thesis/thesisChapter6.pdf" rel="nofollow">http://ttic.uchicago.edu/~gregory/thesis/thesisChapter6.pdf</a> Page 7 talks about the sparse overcomplete code.</p>\n', NULL, NULL, NULL, '2016-04-28', '2016-04-28'),
('["python","arrays","algorithm","numpy","linear-algebra"]', '1', 70, 1, 9, 1458539678, 1457334607, 35838037, 'http://stackoverflow.com/questions/35838037/efficient-reduction-of-multiple-tensors-in-python', 'Efficient reduction of multiple tensors in Python', '<p>I have four multidimensional tensors <code>v[i,j,k]</code>, <code>a[i,s,l]</code>, <code>w[j,s,t,m]</code>, <code>x[k,t,n]</code> in Numpy, and I am trying to compute the tensor <code>z[l,m,n]</code> given by:</p>\n\n<p><code>z[l,m,n] = sum_{i,j,k,s,t} v[i,j,k] * a[i,s,l] * w[j,s,t,m] * x[k,t,n]</code></p>\n\n<p>All the tensors are relatively small (say less that 32k elements in total), however I need to perform this computation many times, so I would like the function to have as little overhead as possible.</p>\n\n<p>I tried to implement it using <code>numpy.einsum</code> like this:</p>\n\n<pre><code>z = np.einsum(''ijk,isl,jstm,ktn'', v, a, w, x)\n</code></pre>\n\n<p>but it was very slow. I also tried the following sequence of <code>numpy.tensordot</code> calls:</p>\n\n<pre><code>z = np.zeros((a.shape[-1],w.shape[-1],x.shape[-1]))\nfor s in range(a.shape[1]):\n  for t in range(x.shape[1]):\n    res = np.tensordot(v, a[:,s,:], (0,0))\n    res = np.tensordot(res, w[:,s,t,:], (0,0))\n    z += np.tensordot(res, x[:,s,:], (0,0))\n</code></pre>\n\n<p>inside of a double for loop to sum over <code>s</code> and <code>t</code> (both <code>s</code> and <code>t</code> are very small, so that is not too much of a problem). This worked much better, but it is still not as fast as I would except. I think this may be because of all the operations that <code>tensordot</code> needs to perform internally before taking the actual product (e.g. permuting the axes).</p>\n\n<p>I was wondering if there is a more efficient way to implement this kind of operations in Numpy. I also wouldn''t mind implementing this part in Cython, but I''m not sure what would be the right algorithm to use.</p>\n', NULL, NULL, NULL, '2016-04-28', '2016-04-28'),
('["time-complexity","linear-algebra"]', '0', 32, 2, 1, 1457735811, 1457392167, 35855978, 'http://stackoverflow.com/questions/35855978/is-omn-in-on2', 'Is O(mn) in O(n^2)?', '<p>Simple question. Working with an m x n matrix and I''m doing some O(mn) operations. My question is if O(mn) is in O(n^2). Looking at the Wikipedia on big O I would think so but I''ve always been pretty bad at complexity bounds so I was hoping someone could clarify.</p>\n', NULL, NULL, NULL, '2016-04-28', '2016-04-28'),
('["python","arrays","numpy","linear-algebra"]', '1', 62, 3, 0, 1457892838, 1457882837, 35972103, 'http://stackoverflow.com/questions/35972103/numpy-dot-products-of-3-matrixes', 'numpy dot products of 3 matrixes', '<p>I''m looking to combine 3 matrixes in a particular way, I''m sure this will be easy for anyone used to using numpy:</p>\n\n<pre><code>w = np.array([[-0.46733567,  0.38864732],\n                 [-0.42436867, -1.08760098],\n                 [-1.01118741,  0.99096466]])   \n\na = array([[ 0.63127368,  0.00167775,  0.97812284]])\n\nd = [[-0.43252997]] # although d is length 1 in this example, its often &gt;1 in length and code needs to be able to generalize, there will always be the same length of cols and and arrays between a and w, i.e in this example there are 3 arrays in w and 1 of length 3 in a (please excuse my terminology, I am new to linear algebra).\n</code></pre>\n\n<p>I am trying to combine them to find dx so that:</p>\n\n<pre><code>dx1 = [-0.46733567,  0.38864732] * 0.63127368 * -0.43252997\ndx2 = [-0.42436867, -1.08760098] * 0.00167775 * -0.43252997\ndx3 = [-1.01118741,  0.99096466] * 0.97812284 * -0.43252997\n</code></pre>\n\n<p>if d is > length 1, e.g. d= np.array([[-0.43252997],[0.87500009]]) then:</p>\n\n<pre><code>dx1_1 = [-0.46733567,  0.38864732] * 0.63127368 * -0.43252997\ndx2_1 = [-0.42436867, -1.08760098] * 0.00167775 * -0.43252997\ndx3_1 = [-1.01118741,  0.99096466] * 0.97812284 * -0.43252997\ndx1_2 = [-0.46733567,  0.38864732] * 0.63127368 * 0.87500009\ndx2_2 = [-0.42436867, -1.08760098] * 0.00167775 * 0.87500009\ndx3_2 = [-1.01118741,  0.99096466] * 0.97812284 * 0.87500009\n</code></pre>\n\n<p>I tried all of these but with seemingly no success, unless I''m missing something?</p>\n\n<pre><code>out = np.dot(d, w) * a \nout = np.dot(d, w) * a.T \nout = np.dot(d, w.T) * a \nout = np.dot(a, w) * d\nout = np.dot(a, w.T) * d\n</code></pre>\n\n<p>I get an error in many cases:</p>\n\n<pre><code>ValueError: shapes (3,1) and (3,2) not aligned: 1 (dim 1) != 3 (dim 0)\n</code></pre>\n\n<p>any pointers to help solve this would be much appreciated</p>\n', NULL, NULL, NULL, '2016-04-28', '2016-04-28'),
('["java","c++","math","linear-algebra","simplex"]', '1', 44, 1, 2, 1457941051, 1457901243, 35975471, 'http://stackoverflow.com/questions/35975471/get-vertexes-of-object-by-simplex-method', 'Get vertexes of object by simplex method', '<p>I''d like to find a vertexes of objects, which is determined by some equations.\nFor example.</p>\n\n<pre><code>Eq1:   2x + y +  z &lt;= 12;\nEq2:    x + y      &gt;= 23;\nEq3:    x + y +  z &lt;= 10;\n</code></pre>\n\n<p>And it''s limited by</p>\n\n<pre><code>x &gt;= 0\ny &gt;= 0\nz =&gt; 0\n</code></pre>\n\n<p>And it gives a hexahedron. I want to know positions of vertexes, which this object is created from. </p>\n\n<p>Is the only way to do this is to make a code that will check all possible variations of this equations?</p>\n\n<pre><code>array = array with this equations (6 elements)\n\nfor( i = 1; i &lt;= array.lenght; i++ ){\n for( j = 1; j &lt;= array.lenght; j++ ){\n  for( k = 1; k &lt;= array.lenght; k++ ){\n    //and there check is solve of a variation is possible\n  }   \n }    \n}\n</code></pre>\n', NULL, NULL, NULL, '2016-04-28', '2016-04-28'),
('["python","python-2.7","matrix","vector","linear-algebra"]', '0', 11, 1, 0, 1457906605, 1457905110, 35976192, 'http://stackoverflow.com/questions/35976192/vector-changes-to-matrix-at-computation', 'vector changes to matrix at computation', '<p>This is probably a rookie mistake that I''m missing somewhere but I can''t for the life of me find anything related to my problem on the web.</p>\n\n<p>I have a vector <code>b1</code> of size <code>5 by 1</code>, and i have another vector <code>dsdb1</code> which is also <code>5 by 1</code>.</p>\n\n<p>When I write <code>b1 += tau*dsdb1</code> I get the error "non-broadcastable output operand with shape (5,1) doesn''t match the broadcast shape (5,5)"</p>\n\n<p>Now, no one of these is a matrix. I even deleted this line and instead printed both sizes for b1 and dsdb1. For b1 it printed (5,1) and for dsdb1 it printed (5,). tau is just a scalar.</p>\n\n<p>Why is it changing dsdb1 to a 5 by 5 matrix when computing?</p>\n', NULL, NULL, NULL, '2016-04-28', '2016-04-28'),
('["python","r","signal-processing","linear-algebra","noise"]', '0', 36, 0, 0, 1457970702, 1457970702, 35992141, 'http://stackoverflow.com/questions/35992141/signal-processing-remove-noise-for-a-series-of-spectra', 'Signal processing-remove noise for a series of spectra', '<p>I am a chemist and measured a series of spectra of one compound under increasing temperature. (-200 degree to 0 degree). The shape of spectra is very similar at different temperature. The only difference is the intensity: at higher temperature the intensity is lower. \nMy problem is at high temperature, e.g. 0 degree, the real signal''s intensity is quite close to the background noise''s amplitude, which make the spectra at high temperature very noisy. I tried some simple smoothing method but the result is not good.\nThe noise is much less affected by the temperature change than the real signal(which means we can assume the background noise doesn''t change too much). Thus, I wonder is there any method that can remove the noise(background) using the series of spectra I have, since they share the "common" background noise. </p>\n\n<p>Any information (e.g. name of method, tools in python or R, reference) will be helpful. Thanks for your help!</p>\n', NULL, NULL, NULL, '2016-04-28', '2016-04-28'),
('["matrix","row","linear-algebra"]', '0', 6, 0, 0, 1457982202, 1457982202, 35995919, 'http://stackoverflow.com/questions/35995919/incremental-sparse-row-echelon-matrix', 'Incremental sparse row echelon matrix', '<p>Assume you have a linear system consisting of an a-priori unknown number of sparse equations. The goal is to define the meaning of the incremental "add an equation" operation:</p>\n\n<ul>\n<li>The input is the current system in row-echelon form and a new equation represented by a sparse vector of coefficients for each unknowns and a constant. The vector can have an arbitrary dimension (hence the system can grow in size) </li>\n<li>The output is the new system in row echelon form.</li>\n</ul>\n\n<p>In order to maintain the row echelon form, my idea is to do the following:</p>\n\n<ul>\n<li>Proceed through the non-zero entries of the vector in order:\n\n<ul>\n<li>if the system already contains a row with this element being the leading element:\n\n<ul>\n<li>multiply the existing row with the coefficient found in the vector, subtract the result from the vector and start again</li>\n</ul></li>\n<li>else divide the vector by the coefficient and add as a new row to the matrix</li>\n</ul></li>\n</ul>\n\n<p>Is this algorithm correct? Did I miss any corner cases? Is there a more efficient, canonical variant? </p>\n', NULL, NULL, NULL, '2016-04-28', '2016-04-28'),
('["matlab","matrix","linear-algebra"]', '1', 46, 1, 0, 1457988238, 1457985101, 35996761, 'http://stackoverflow.com/questions/35996761/matlab-creating-matrix-with-multiple-diagonals-using-diag', 'MATLAB: creating matrix with multiple diagonals using diag()', '<p>I need to make a matrix that looks like this by using diag command from MATLAB.</p>\n\n<pre><code>    [0  0  7  0  2;\n     0  0  0  3  0;\n     0  0  0  0  1;\n     0  0  0  0  0;\n     0  0  0  0  0]\n</code></pre>\n\n<p>I figured how to do</p>\n\n<pre><code>    [0  0  7  0  0;\n     0  0  0  3  0;\n     0  0  0  0  1;\n     0  0  0  0  0;\n     0  0  0  0  0]\n</code></pre>\n\n<p>But can''t seems to insert 2 at the first row/fifth column.</p>\n', NULL, NULL, NULL, '2016-04-28', '2016-04-28'),
('["normalization","linear-algebra","raytracing"]', '1', 63, 1, 0, 1458088714, 1458023433, 36004155, 'http://stackoverflow.com/questions/36004155/finding-normal-of-sphere-in-ray-tracer-porgram', 'Finding Normal of Sphere in Ray Tracer Porgram', '<p>I''m working on a ray tracer for spheres and I''m trying to implement an illuminate function to calculate the light intensity per ray. I''m currently stuck on calculating the diffuse reflection:</p>\n\n<p>Given a ray R, a sphere S, a point P where R intersects S, and a light source L</p>\n\n<p>I understand that to use Lambert''s Law to calculate diffuse reflection, I need the light direction vector and the normal vector. </p>\n\n<p>I know I can get the light direction vector by calculating L - P. I''m stuck now on calculating the normal. </p>\n\n<p>I know I need to use the inverse of the S transform matrix but I don''t understand conceptually what inverting the S transform matrix does so I was hoping to get some guidance on how to do this. </p>\n', NULL, NULL, NULL, '2016-04-28', '2016-04-28'),
('["algorithm","linear-algebra","sparse-matrix"]', '1', 21, 1, 0, 1458112116, 1458051244, 36013785, 'http://stackoverflow.com/questions/36013785/how-to-find-non-zero-elements-of-matrix-at-a-where-a-is-sparse-crs-ccs-matr', 'How to find non-zero elements of matrix A^T * A where A is sparse (crs/ccs) matrix?', '<p>I have very sparse large matrix <code>A</code> (<code>A</code> is a <a href="https://en.wikipedia.org/wiki/Sparse_matrix#Compressed_sparse_row_.28CSR.2C_CRS_or_Yale_format.29" rel="nofollow">compressed row storage</a>)</p>\n\n<p>I want to perform some computations over <code>B = A^T * A</code> matrix. But <code>B</code> should be sparse too due sparsity of <code>A</code>.</p>\n\n<p>How i can compute "mask" of <code>B</code>? "Mask" is column indices and row offsets of compressed row storage.</p>\n\n<p>Only way which i see is to iterate over rows in nested loops (by i and j) and check (i, j) element of B as non-zero if rows i and j of A have at least one common non-zero column. But i think is slow.</p>\n\n<p>PS Sorry for my poor english</p>\n', NULL, NULL, NULL, '2016-04-28', '2016-04-28');
INSERT INTO `so_questions` (`tags`, `is_answered`, `view_count`, `answer_count`, `score`, `last_activity_date`, `creation_date`, `question_id`, `link`, `title`, `body`, `has_more`, `quota_max`, `quota_remaining`, `createdAt`, `updatedAt`) VALUES
('["php","linear-algebra","algebra"]', '1', 34, 1, 0, 1458112484, 1458076513, 36022304, 'http://stackoverflow.com/questions/36022304/phps-gauss-jordan-elimination-code', 'php&#39;s Gauss-Jordan Elimination code', '<p>I''d like to write a code to make gaussian elimination, i got this:</p>\n\n<pre><code>function gauss($A, $x) {\n\n    for ($i=0; $i &lt; count($A); $i++) {\n        $A[$i][] = $x[$i];\n    }\n    $n = count($A);\n\n    for ($i=0; $i &lt; $n; $i++) {\n        $maxEl = abs($A[$i][$i]);\n        $maxRow = $i;\n        for ($k=$i+1; $k &lt; $n; $k++) {\n            if (abs($A[$k][$i]) &gt; $maxEl) {\n                $maxEl = abs($A[$k][$i]);\n                $maxRow = $k;\n            }\n        }\n\n\n        for ($k=$i; $k &lt; $n+1; $k++) {\n            $tmp = $A[$maxRow][$k];\n            $A[$maxRow][$k] = $A[$i][$k];\n            $A[$i][$k] = $tmp;\n        }\n\n        for ($k=$i+1; $k &lt; $n; $k++) {\n            $c = -$A[$k][$i]/$A[$i][$i];\n            for ($j=$i; $j &lt; $n+1; $j++) {\n                if ($i==$j) {\n                    $A[$k][$j] = 0;\n                } else {\n                    $A[$k][$j] += $c * $A[$i][$j];\n                }\n            }\n        }\n    }\n\n    $x = array_fill(0, $n, 0);\n    for ($i=$n-1; $i &gt; -1; $i--) {\n        $x[$i] = $A[$i][$n]/$A[$i][$i];\n        for ($k=$i-1; $k &gt; -1; $k--) {\n            $A[$k][$n] -= $A[$k][$i] * $x[$i];\n        }\n    }\nif (!in_array(false, $x, true)){\n if($x[0] &gt;= 0 &amp;&amp; $x[1] &gt;= 0 &amp;&amp; $x[2] &gt;= 0){\nreturn $x;\n}\n}\n\n}\n</code></pre>\n\n<p>Everything is OK but when i put values like this:</p>\n\n<pre><code>$A = array(array(1,1,0),array(3,5,4),array(1,0,0));\n$x = array(2,30,0);\n\n\n\n| 1 1 0 |  2 | \n| 1 0 0 |  0 |\n| 3 5 4 | 30 |\n</code></pre>\n\n<p>The result should be: (0,2,5), but my function returns null. </p>\n\n<p>I don''t know what is wrong with it.</p>\n', NULL, NULL, NULL, '2016-04-28', '2016-04-28'),
('["python","math","linear-algebra"]', '0', 77, 1, 4, 1458224343, 1458218787, 36060975, 'http://stackoverflow.com/questions/36060975/how-to-compute-smallest-non-zero-eigenvalue', 'How to compute smallest non-zero eigenvalue', '<p>Given a positive semi-definite matrix M I would like to find its smallest non-zero eigenvalue. In python this code looks tempting</p>\n\n<pre><code>import numpy as np\n(w,v) = np.linalg.eigh(M)\nminw = np.amin(w)\nif (np.isclose(minw,0) and minw &gt; 0):\n    print M, minw\n</code></pre>\n\n<p>Here is an example small input matrix.</p>\n\n<pre><code>[ 6  2 -4 -2]\n[ 2  6  0 -6]\n[-4  0  6  0]\n[-2 -6  0  6]\n</code></pre>\n\n<p>Unfortunately if you try this you will get <code>8.90238403828e-16</code>.  I don''t know in general how to tell if very small numbers are meant to be zero or not.</p>\n\n<p>How can you find the smallest non-zero eigenvalue of a matrix (and be sure it really is non-zero)?</p>\n', NULL, NULL, NULL, '2016-04-28', '2016-04-28'),
('["c#","linear-algebra","mathnet"]', '0', 25, 0, 0, 1458220231, 1458220231, 36061535, 'http://stackoverflow.com/questions/36061535/how-to-generate-sub-matrix-from-matrix-with-headers-and-list-of-headers', 'How to generate sub matrix from matrix with headers and list of headers?', '<p>I have a type <code>SymmetricMatrixWithHeaders</code> with a general structure like this </p>\n\n<pre><code>public class SymmetricMatrixWithHeaders&lt;T&gt; \n    {\n        private readonly Dictionary&lt;T, int&gt; _columnHeadersWithIndices = \n                                                 new Dictionary&lt;T, int&gt;();\n        private readonly Dictionary&lt;T, int&gt; _rowHeadersWithIndices = \n                                                 new Dictionary&lt;T, int&gt;();\n        private readonly Matrix&lt;double&gt; _data;\n\n        public MatrixWithHeaders(\n            List&lt;T&gt; columnHeaders,\n            Matrix&lt;double&gt; data \n            )\n        {\n            // ensure matrix is symmetric here\n            // set row headers the same as column headers (since symmetric)\n        }\n        // methods to fetch _data, headers, a few other things. \n    }\n</code></pre>\n\n<p>Note that <code>Matrix&lt;double&gt;</code> is a <a href="http://numerics.mathdotnet.com/api/MathNet.Numerics.LinearAlgebra/Matrix%601.htm" rel="nofollow"><code>MathNet.Numerics.LinearAlgebra.Matrix</code></a> type.</p>\n\n<p>Now I want to create a static method that is passed a full symmetric matrix and a list of headers as parameters, and returns a new symmetric matrix with only those passed headers included as rows/columns.  I''m having a hard time finding any useful facilities in <a href="http://numerics.mathdotnet.com/api/MathNet.Numerics.LinearAlgebra/" rel="nofollow">MathNet.Numerics.LinearAlgebra</a> to help me assign a new matrix to only those headers passed to my method. Is there a nice way to do this? Or will the inevitable solution be simply reading the matrix row by row into some enumerable based on the column/row headers and then generating a new matrix from the enumerable?</p>\n\n<pre><code>public static MatrixWithHeaders&lt;T&gt; GenerateSubSymmetricMatrix(\n            MatrixWithHeaders&lt;T&gt; fullSymmetricMatrix, List&lt;T&gt; neededFactors)\n    {\n         // create matrix of only those columns/rows with headers in neededFactors\n    }\n</code></pre>\n', NULL, NULL, NULL, '2016-04-28', '2016-04-28'),
('["matlab","linear-algebra"]', '1', 45, 1, 2, 1459349639, 1458274967, 36076094, 'http://stackoverflow.com/questions/36076094/how-can-i-choose-gaussian-elimination-to-solve-ax-b-in-matlab', 'How can I choose Gaussian Elimination to solve Ax=b in MATLAB?', '<p>I have a question about solving linear equation <code>Ax=b</code>, in which <code>x</code> is unknown, A is square matrix <code>NxN</code> and non-singular matrix.</p>\n\n<p>The vector <code>x</code> can be solved by </p>\n\n<pre><code>x=inv(A)*b \n</code></pre>\n\n<p>or</p>\n\n<pre><code>x=A\\b \n</code></pre>\n\n<p>In Matlab, the ‘\\’ command invokes an algorithm which depends upon the structure of the matrix A and includes checks (small overhead) on properties of A. Hence, It highly depends on A structure. However, A structure is unknown (i.e random matrix). I want to measure complexity of above equation. Hence, to fairly comparison, I need to fixed the method which I used. In this case, I choose Gaussian Elimination (GE) with complexity <code>O(N^3)</code> My question is how can I choose/fix the method (i.e. GE) to solve above equation? </p>\n', NULL, NULL, NULL, '2016-04-28', '2016-04-28'),
('["algorithm","matlab","machine-learning","linear-algebra","linear-regression"]', '0', 52, 1, 0, 1458575381, 1458403608, 36103949, 'http://stackoverflow.com/questions/36103949/line-projected-linear-discriminant-analysis', 'Line Projected - Linear discriminant analysis', '<p>I have two question. \nI have the attached code for linear discriminant analysis, that deals with two classes -each two features. It is the very basic one. \nHowever,</p>\n\n<p>I don''t know why my projected line is not the same as the tutorial. Please tell me where is the wrong implementation I did with respect to pdf attached.   </p>\n\n<p><a href="http://research.cs.tamu.edu/prism/lectures/pr/pr_l10.pdf" rel="nofollow">http://research.cs.tamu.edu/prism/lectures/pr/pr_l10.pdf</a>\n<a href="http://www.di.univr.it/documenti/OccorrenzaIns/matdid/matdid437773.pdf" rel="nofollow">http://www.di.univr.it/documenti/OccorrenzaIns/matdid/matdid437773.pdf</a></p>\n\n<pre><code>% Fisher''s linear discriminant. \n% : xi is column vector of which element is test metric. \n% Therefore size of row is the number of test metrics. \n% Number of column is the number of data sets. \n% x1 = rand(2, 30) + 0.75.*ones(2,30); %[d1(:,c1) d1(:,c2)]'';\n% x2 = rand(2, 30) + 0.3 .*ones(2,30); %[d2(:,c1) d2(:,c2)]'';\nx1=[1 2;2 3;3 3;4 5;5 5]''  % the first class 5 observations\nx2=[1 0;2 1;3 1;3 2;5 3]'' % the second class 6 observations\nm1 = mean(x1'')''; \nm2 = mean(x2'')''; \nm = m1 + m2; \nSw1 = zeros(size(x1, 1), size(x1,1)); \nSw2 = zeros(size(x1, 1), size(x1,1)); \n   for i = 1:size(x1,1)\n       Sw1 =  Sw1 + (x1(:,i)-m1)*(x1(:,i)-m1)'';\n   end\n  for i = 1:size(x2,1)\n     Sw2 =  Sw2 + (x2(:,i)-m2)*(x2(:,i)-m2)'';\n  end\n\n Sw = Sw1 + Sw2; \n w = Sw^(-1)*(m2-m1);\n  scatter(x1(1,:), x1(2,:), 10, ''ro'');\nhold on;\nscatter(x2(1,:), x2(2,:),10,''bo'');\nc = 0.5.*m; %Average mean.ie. m/2\nquiver(c(1,1), c(2,1), 1, -w(1,1)/w(2,1));\nquiver(c(1,1), c(2,1), -1, w(1,1)/w(2,1));\nquiver(w(1,1),w(2,1), 0.5)\nhold off;\nfigure; \ny1 = x1''*w; \ny2 = x2''*w; \nhist([y1 y2])\nnewy=w''*newp;\n%newp is new point\ndiff1=abs(m1-newy);\ndiff2=abs(m2-newy);\nif diff1 &gt;=diff2\n  %newp is included in class1\nelse\n\n%newp is included in class2\n\n\n It has to be something similar to the following picture\n\n[![smthg simialr to the following final results][3]][3]\n</code></pre>\n', NULL, NULL, NULL, '2016-04-28', '2016-04-28'),
('["python","numpy","computer-vision","vectorization","linear-algebra"]', '0', 31, 0, 0, 1458428111, 1458428111, 36108213, 'http://stackoverflow.com/questions/36108213/using-numpy-to-find-all-possible-distance-vectors-in-a-coordinate-grid', 'Using numpy to find all possible distance vectors in a coordinate grid', '<p>I''m trying to implement Fabian Timm''s pupil tracking algorithm [<a href="http://www.inb.uni-luebeck.de/publikationen/pdfs/TiBa11b.pdf]" rel="nofollow">http://www.inb.uni-luebeck.de/publikationen/pdfs/TiBa11b.pdf]</a> and the equation requires that I find all possible distance vectors within a coordinate grid. My implementation isn''t working correctly, and I think it''s because of this step. I know I should speed up my implementation using broadcasting, but any insight into other possible improvements would be appreciated. I would also be curious to know any tricks to testing code like this. Did I do this right?</p>\n\n<pre><code>eye_len = np.arange(eye.shape[0]) # this is usually in the range of 30-40\nxx,yy = np.meshgrid(eye_len,eye_len) # coordinates of every point in the eye image\nX1,X2 = np.meshgrid(xx.ravel(),xx.ravel())\nY1,Y2 = np.meshgrid(yy.ravel(),yy.ravel())\nDx,Dy = [X1-X2,Y1-Y2]\nDlen = np.sqrt(Dx**2+Dy**2)\nDx,Dy = [Dx/Dlen, Dy/Dlen] #normalized\n</code></pre>\n', NULL, NULL, NULL, '2016-04-28', '2016-04-28'),
('["image","linear-algebra","svd","homography"]', '0', 16, 0, 0, 1458571417, 1458571417, 36134113, 'http://stackoverflow.com/questions/36134113/using-svd-how-to-do-image-homograpy', 'Using SVD, how to do Image homograpy', '<p>I want image homography by applying the homography matrix h.</p>\n\n<p>The homography matrix h is obtained by selecting column of matrix V in the singular value decomposition (SVD) corresponding to the smallest singular value.</p>\n\n<p>For example, The matrix D is obtained by [U D V] = SVD(A). The matrix D is below.\n<a href="http://i.stack.imgur.com/WDLfo.png" rel="nofollow"><img src="http://i.stack.imgur.com/WDLfo.png" alt="enter image description here"></a></p>\n\n<p>I don''t know the smallest singular value exactly. However, I know that the homography matrix h is obtained by selecting 9th column of matrix V.</p>\n\n<p>In other words, I have to select the smallest singluar value as 9th diagonal element form the matrix D. Is it false if I select the smallest singular value as 11.6333?</p>\n\n<p>Please explain about it.\nCould you expalain how to select the smallest singular value from the matrix D?</p>\n\n<p>Thanks.</p>\n', NULL, NULL, NULL, '2016-04-28', '2016-04-28'),
('["matrix","linear-algebra","eigenvalue","eigenvector"]', '0', 24, 0, 0, 1458596880, 1458596019, 36142041, 'http://stackoverflow.com/questions/36142041/power-iteration-method-for-n-largest-eigenvalues', 'Power iteration method for n largest eigenvalues', '<p>I do a Power Iteration on matrix M to get n dominant eigenvalues.</p>\n\n<pre><code>M1 = [0.4170    0.0001; 0.7203    0.3023]\n</code></pre>\n\n<p>Within my first iteration I would get the following results:</p>\n\n<pre><code>eigenvector1: [0.1582     0.9874]\neigenvalue1:  [0.4177]\n</code></pre>\n\n<p>But due to my algorithm I only have the first dominant eigenvector normalized by the maximum and the eigenvalue:</p>\n\n<pre><code> eigenvectorNorm: [0.1602     1.000]\n eigenvalue1:  [0.4177]\n</code></pre>\n\n<p>Normally I would now do the following calculation to get my next initial matrix: </p>\n\n<pre><code> M2 = M1 - eigenvalue1 * eigenvector1 * transpose(eigenvector1) \n</code></pre>\n\n<p>instead I would do: </p>\n\n<pre><code> M2 = M1 - eigenvalue1 * eigenvectorNorm * transpose(eigenvectorNorm) \n</code></pre>\n\n<p>But unfortunately it does not work. I get a wrong second eigenvalue... What do I have to do to make this work correctly?</p>\n', NULL, NULL, NULL, '2016-04-28', '2016-04-28'),
('["c++","algorithm","linear-algebra","maximization"]', '1', 75, 1, 2, 1458615570, 1458609025, 36144528, 'http://stackoverflow.com/questions/36144528/c-algorithm-for-solving-maximisation-in-linear-programming', 'C++ Algorithm for solving maximisation in linear programming', '<p>I am learning about maximisation with linear programming, and have come across an algorithm for maximisation with two variables (<strong>silver</strong> and <strong>gold</strong> in this instance) but I am unsure what a certain section of the code is doing:</p>\n\n<pre><code>using namespace std;\n\n\nclass PreciousStones {\n  int n;\n  vector&lt;int&gt; as;\n  vector&lt;int&gt; ag;\n</code></pre>\n\n<p>The function below is the section I am unclear on:</p>\n\n<pre><code>  double maxg (double s) {\n    double g = 0;\n    for (int i=0; i&lt;n; i++)\n      if (s == 0)\n        g += ag[i];\n      else if (as[i] &lt;= s) \n        s -= as[i];\n      else {\n        g += (1-s/as[i])*ag[i];\n        s = 0;\n      }\n    return g;\n  }\n</code></pre>\n\n<p>The rest of the code is below (for context), if anyone knows of some relevant papers on this algorithm, or can provide a brief explanation on this function I would appreciate it greatly</p>\n\n<pre><code>public:\n  double value(vector &lt;int&gt; silver, vector &lt;int&gt; gold) {\n    n = silver.size();\n    as = silver;\n    ag = gold;\n    for (int i=0; i&lt;n; i++) \n      for (int j=i+1; j&lt;n; j++) \n        if (as[j]*ag[i] &gt; as[i]*ag[j]) {\n          swap(as[i], as[j]);\n          swap(ag[i], ag[j]);\n        }\n    double lo = 0;\n    double hi = 51*100;\n    double D = 1e-10;\n    while (lo+D &lt; hi &amp;&amp; lo*(1+D) &lt; hi) {\n      double mid = (lo+hi)/2;\n      if (mid &lt;= maxg(mid))\n        lo = mid;\n      else\n        hi = mid;\n    }\n    return lo;\n  }\n}; \n</code></pre>\n', NULL, NULL, NULL, '2016-04-28', '2016-04-28'),
('["python","numpy","linear-algebra","svd"]', '1', 25, 1, 0, 1458665239, 1458651272, 36154950, 'http://stackoverflow.com/questions/36154950/can-i-get-data-spread-noise-from-singular-value-decomposition', 'Can I get data spread (noise) from singular value decomposition?', '<p>I''m was hoping to use singular value decomposition to estimate the standard deviation of eliptoid data.  I''m not sure if this is the best approach and I may be overthinking the entire process so I need some help.</p>\n\n<p>I simulated some data using the following script...</p>\n\n<pre><code>from matplotlib import pyplot as plt\nimport numpy\n\n\ndef svd_example():\n    # simulate some data...\n    # x values have standard deviation 3000\n    xdata = numpy.random.normal(0, 3000, 5000).reshape(-1, 1)\n    # y values standard deviation 300\n    ydata = numpy.random.normal(0, 300, 5000).reshape(-1, 1)\n    # apply some rotation\n    ydata_rotated = ydata + (xdata * 0.5)\n    data = numpy.hstack((xdata, ydata_rotated))\n\n    # get singular values\n    left_singular_matrix, singular_values, right_singular_matrix = numpy.linalg.svd(data)\n    print ''singular values'', singular_values\n\n    # plot data....\n    plt.scatter(data[:, 0], data[:, 1], s=5)\n    plt.ylim(-15000, 15000)\n    plt.show()\n\nsvd_example()\n</code></pre>\n\n<p>I get singular values of...</p>\n\n<pre><code>&gt;&gt;&gt; singular values [ 234001.71228678   18850.45155942]\n</code></pre>\n\n<p>My data looks like this...</p>\n\n<p><a href="http://i.stack.imgur.com/eD79S.png" rel="nofollow"><img src="http://i.stack.imgur.com/eD79S.png" alt="enter image description here"></a></p>\n\n<p>I was under the assumption that the singular values would give me some indication of the spread of data regardless of it''s rotation, right?  But these values, [234001.71228678   18850.45155942], make no sense to me.  My standard deviations were 3000 and 300.  Do these singular values represent variance?  How do I convert them? </p>\n', NULL, NULL, NULL, '2016-04-28', '2016-04-28'),
('["math","3d","linear-algebra"]', '0', 26, 1, 1, 1458770087, 1458652779, 36155478, 'http://stackoverflow.com/questions/36155478/projection-of-points-on-plane-and-the-inverse-transformation', 'Projection of points on plane and the inverse transformation', '<p>i''m working on a project where i have a cloud of points in space as input data, my goal is to create a surface.</p>\n\n<p>I started by computing a regression plan for the cloud, then i projected my points on the plane using dot products : </p>\n\n<p>My plane is represented by a point and a normal , i construct the axis of the plane''s space using cross products then project each point on these axis.</p>\n\n<p>then i triangulate in 2D (that''s the point of the whole operation).</p>\n\n<p>My problem is that my points now are in the plane space and i want to get them back to their inital position (inverse the transformation) to have my surface ON my points.</p>\n\n<p>thank you :)</p>\n', NULL, NULL, NULL, '2016-04-28', '2016-04-28'),
('["linear-algebra","sparse-matrix","eigen","preconditions"]', '1', 68, 2, 1, 1458992953, 1458786007, 36192186, 'http://stackoverflow.com/questions/36192186/which-sparse-linear-solver-is-faster-sparselu-or-bicgstab', 'Which sparse linear solver is faster? SparseLU or BiCGSTAB?', '<p>I tested Eigen''s SparseLU and BicGSTAB method on some sparse matrix, whose dense counterparts'' size ranges from 3000*3000 to 16000*16000. All the cases shows that SparseLU is around 13% faster than BicGSTAB method. </p>\n\n<p>I didn''t feed the BiCGSTAB a RowMajor sparse matrix, or give it any pre-conditioner. That might be the reason of slow.</p>\n\n<p>So I am wondering, if I do both methods well, which one should be faster?</p>\n\n<p>How about if the matrix size goes up to millions*millions?</p>\n\n<p>Thanks a lot!</p>\n', NULL, NULL, NULL, '2016-04-28', '2016-04-28'),
('["python","linear-algebra"]', '0', 26, 0, 1, 1458837002, 1458837002, 36205248, 'http://stackoverflow.com/questions/36205248/python-dealing-with-repeated-eigenvalues', 'Python dealing with repeated eigenvalues', '<p>Consider A a real symmetric matrix and</p>\n\n<pre><code>import scipy\n(s,u)=scipy.linalg.eigh(A)\n</code></pre>\n\n<p>If A has repeated eigenvalues then the columns of u are not necessarily orthonormal. What is the most efficient way to obtain a basis of orthonormal eigenvectors in python?</p>\n', NULL, NULL, NULL, '2016-04-28', '2016-04-28'),
('["python","numpy","linear-algebra"]', '1', 26, 1, 2, 1459115748, 1458921339, 36223341, 'http://stackoverflow.com/questions/36223341/numpy-linalg-pinv-hangs-for-some-infinite-values-but-not-for-others', 'numpy.linalg.pinv() hangs for some infinite values (but not for others)', '<p>In my code I need to compute pseudoinverse of matrices and it may happen that some of the elements of the matrix are infinite (<code>np.inf</code>). Sometimes the <code>pinv()</code> function handles it well and returns something, but sometimes it just hangs with 100% CPU usage and I need to kill the process. See the demonstration below:</p>\n\n<pre><code>Python 3.4.3+ (default, Oct 14 2015, 16:03:50) \nType "copyright", "credits" or "license" for more information.\n\nIPython 4.1.2 -- An enhanced Interactive Python.\n?         -&gt; Introduction and overview of IPython''s features.\n%quickref -&gt; Quick reference.\nhelp      -&gt; Python''s own help system.\nobject?   -&gt; Details about ''object'', use ''object??'' for extra details.\n\nIn [1]: import numpy as np\nIn [2]: import numpy.linalg as la\nIn [3]: x = np.array([[550.0, 1], [1, np.inf]])\nIn [4]: la.pinv(x)\nOut[4]: \narray([[ 0.,  0.],\n       [ 0.,  0.]])\nIn [5]: x = np.array([[np.inf, np.inf], [np.inf, np.inf]])\nIn [6]: la.pinv(x)\nOut[6]: \narray([[ nan,  nan],\n       [ nan,  nan]])\nIn [7]: x = np.array([[550.0, 1], [np.inf, np.inf]])\nIn [8]: la.pinv(x)  # here it just hung and I had to kill it from outside\nKilled\n</code></pre>\n\n<p>Why does this happen? Why does it do fine for some arrangement of <code>inf</code>s but it just hangs for other? Might this be a bug (i.e. should the values be checked first)?</p>\n', NULL, NULL, NULL, '2016-04-28', '2016-04-28'),
('["matlab","opencv","linear-algebra","basis"]', '0', 15, 0, 1, 1459019949, 1459018689, 36239521, 'http://stackoverflow.com/questions/36239521/computing-null-space-via-opencv', 'computing null space via opencv', '<p>Is there an alternative command in OpenCV to <code>null</code> command in MATLAB, which given a vector <code>v</code> computes an orthogonal basis for the null space which <code>v</code> is one of its basis vectors?</p>\n', NULL, NULL, NULL, '2016-04-28', '2016-04-28'),
('["python","arrays","numpy","matrix","linear-algebra"]', '1', 49, 2, 3, 1459105916, 1459101767, 36250729, 'http://stackoverflow.com/questions/36250729/convert-triangle-matrix-to-square-python-numpy', 'Convert triangle matrix to square (Python | NumPy)?', '<p>I''m doing some computations  on a full matrix that is redundant (i.e. can be a triangle matrix w/o losing info).  I realized I can compute only the lower portion of the triangle for faster results. How can I project the lower triangle into the upper once I''m done?</p>\n\n<p><strong>In other words, how can I reverse the <code>np.tril</code> method?</strong> </p>\n\n<pre><code>print DF_var.as_matrix()\n# [[1 1 0 1 1 1 0 1 0 0 0]\n#  [1 1 1 1 1 0 1 0 1 1 1]\n#  [0 1 1 0 0 0 0 0 0 0 0]\n#  [1 1 0 1 0 0 0 0 0 0 0]\n#  [1 1 0 0 1 0 0 0 0 0 0]\n#  [1 0 0 0 0 1 1 0 0 0 0]\n#  [0 1 0 0 0 1 1 0 0 0 0]\n#  [1 0 0 0 0 0 0 1 1 0 0]\n#  [0 1 0 0 0 0 0 1 1 0 0]\n#  [0 1 0 0 0 0 0 0 0 1 0]\n#  [0 1 0 0 0 0 0 0 0 0 1]]\nprint np.tril(DF_var.as_matrix())\n# [[1 0 0 0 0 0 0 0 0 0 0]\n#  [1 1 0 0 0 0 0 0 0 0 0]\n#  [0 1 1 0 0 0 0 0 0 0 0]\n#  [1 1 0 1 0 0 0 0 0 0 0]\n#  [1 1 0 0 1 0 0 0 0 0 0]\n#  [1 0 0 0 0 1 0 0 0 0 0]\n#  [0 1 0 0 0 1 1 0 0 0 0]\n#  [1 0 0 0 0 0 0 1 0 0 0]\n#  [0 1 0 0 0 0 0 1 1 0 0]\n#  [0 1 0 0 0 0 0 0 0 1 0]\n#  [0 1 0 0 0 0 0 0 0 0 1]]\n</code></pre>\n\n<p><strong>How to convert it back to a full matrix?</strong> </p>\n', NULL, NULL, NULL, '2016-04-28', '2016-04-28'),
('["python","linear-algebra"]', '0', 22, 1, 1, 1459212213, 1459195164, 36270116, 'http://stackoverflow.com/questions/36270116/how-do-i-define-a-hyperplane-in-python-given-4-points-how-do-i-then-define-the', 'How do I define a hyperplane in Python given 4 points? How do I then define the intersection of 4 hyperplanes (this should be a point)?', '<p>I have 4 points in R4 and their co-ordinates:</p>\n\n<pre><code>P1:[x1, y1, z1, w1] \nP2:[x2, y2, z2, w2]\nP3:[x3, y3, z3, w3]\nP4:[x4, y4, z4, w4]\n</code></pre>\n\n<p>How do I now define a hyperplane out of these points  in Python?</p>\n\n<p>Also given that I have the equations of 4 hyperplanes how do I get their intersection (which should be a point)?</p>\n\n<p>Thanks!\nO.</p>\n', NULL, NULL, NULL, '2016-04-28', '2016-04-28'),
('["linear-algebra","linear-programming","linear"]', '0', 28, 0, 0, 1459201962, 1459201962, 36271861, 'http://stackoverflow.com/questions/36271861/is-there-a-way-to-find-if-there-exists-a-solution-such-that-all-the-variables-in', 'Is there a way to find if there exists a solution such that all the variables in a system of linear equations are either 0 or 1 in P time?', '<p>Note this is different from Binary Integer Programming as it does not involve inequalities.</p>\n\n<p>An example would be a+b = 1. A solution would be a = 0, b = 1. I just want 1 solution, or even if there exists a solution. I think this should be possible but have no idea how to proceed about it. I was reading this <a href="http://www.math.rutgers.edu/~sk1233/courses/ANT-F14/lec3.pdf" rel="nofollow">http://www.math.rutgers.edu/~sk1233/courses/ANT-F14/lec3.pdf</a> where they can find integer solutions in P time, I was not sure how this can be switched to find solutions which are only 0 or 1.</p>\n\n<p>It would be great if it could be explained in easy terms so a 2nd-3rd year math/cs student in college could understand. And if anyone can provide a solver or a library or code which can solve it would be of great great help.</p>\n\n<p>Thanks!</p>\n', NULL, NULL, NULL, '2016-04-28', '2016-04-28'),
('["matlab","matrix","linear-algebra"]', '1', 23, 3, 0, 1459253016, 1459218250, 36274315, 'http://stackoverflow.com/questions/36274315/simple-matrix-matlab-mannipulation', 'Simple Matrix matlab mannipulation', '<p>This question relates to basic linear algebra:</p>\n\n<pre><code>w = [100 200 300 400]'' \nM = [0.3378 0.1800;0.1252 0.1200; 0.3759 0.4900; 0.1611 0.2100]\n</code></pre>\n\n<p>The equation relating them is w = Mx. We are told to find x. While x is just simply w*M^-1, the matrix dimensions do not match for the multiplication. Is there a way for me to obtain x? </p>\n\n<p>The hint given to us is to "check rref([M w]) to see if the equation relating x and w is consistent."</p>\n', NULL, NULL, NULL, '2016-04-28', '2016-04-28'),
('["python","python-3.x","linear-algebra"]', '0', 35, 0, 0, 1459310769, 1459310465, 36299442, 'http://stackoverflow.com/questions/36299442/how-to-solve-linear-algebra-equation-az-b-where-z-is-non-positive-python', 'How to solve Linear Algebra equation Az=b where z is non-positive? [PYTHON]', '<p>Hi I want to solve a Linear Algebra equation <code>Az = B</code> where the <strong><em>output matrix variables are</em></strong> <strong><em>non-positive</em></strong>.</p>\n\n<p><em>example.</em></p>\n\n<pre><code>A = np.array([[1,2]\n              [3,4]]\n\nb = np.array([1,2])\n\nz = [x,y]\n</code></pre>\n\n<p>solving using <code>z = np.linalg.solve(A,b)</code> gives me both positive and negative variables for <code>x</code> and <code>y</code>.I want the variables to be <code>-x</code> and <code>-y</code>. How do I do this? Thank you so much!</p>\n', NULL, NULL, NULL, '2016-04-28', '2016-04-28'),
('["vector","linear-algebra","calculus"]', '0', 22, 1, 0, 1459342978, 1459342032, 36309328, 'http://stackoverflow.com/questions/36309328/why-dot-product-of-vectors-perpendicular-to-normal-vector-is-equal-to-zero', 'Why dot product of vectors perpendicular to normal vector is equal to zero?', '<p>Why dot product of vectors perpendicular to normal vector is equal to zero?</p>\n\n<p>Please follow the link <a href="http://www.maths.usyd.edu.au/u/MOW/vectors/vectors-13/v-13-1.html" rel="nofollow">vector equation of a plane</a> to get short description and figure.</p>\n\n<p>On above link you could find dot product (r - r_o) . n = 0. Please provide brief and simple explanation for why it''s equal to zero. I have already searched numerous websites as most of them provide the reason behind this is because it''s perpendicular to normal vector, there has to be better explanation.</p>\n\n<p>Thank you for your time.</p>\n', NULL, NULL, NULL, '2016-04-28', '2016-04-28'),
('["matlab","vector","linear-algebra","matlab-figure","projection"]', '1', 57, 1, 0, 1459444261, 1459383975, 36322123, 'http://stackoverflow.com/questions/36322123/draw-the-vector-w-as-well-as-the-projection-of-another-vector-onto-w', 'Draw the vector w as well as the projection of another vector onto w', '<p>How can I <strong>plot</strong> the vector <strong>w</strong> with the projected data onto this vector?\nHere is the code - and my trials to plot the weight vector with <strong>y1</strong> and <strong>y2</strong>.</p>\n\n<pre><code>x1=[1 2;2 3;3 3;4 5;5 5]  % the first class 5 observations\nx2=[1 0;2 1;3 1;3 2;5 3;6 5]\nm1 = mean(x1); \nm2 = mean(x2); \nm = m1 + m2; \nd1=x1-repmat(m1,5,1);\nd2=x2-repmat(m2,6,1);\nc = 0.5.*m; \nSw1 = d1''*d1;\nSw2 = d2''*d2;\nSw = Sw1 + Sw2; \ninvSw = inv(Sw);\nw= invSw*(m1-m2)'' %this is my vector projected\nscatter(x1(:,1), x1(:,2), 10, ''ro'');\nhold on;\nscatter(x2(:,1), x2(:,2), 10,''bo'');\n%this is how i plot the decision boundary, but it doesn''t seems correct. \nquiver(c(1,1), c(1,2), 1, -w(1,1)/w(2,1));\nquiver(c(1,1), c(1,2), -1, w(1,1)/w(2,1));\n\nauxw= w/norm(w);\nplot([0 auxw(1)], [0 auxw(2)]) \nhold off;\nfigure; \ny1 = x1*w; \ny2 = x2*w; \nhist([y1'' y2''])\n</code></pre>\n', NULL, NULL, NULL, '2016-04-28', '2016-04-28'),
('["svm","vectorization","linear-algebra","matlab-figure","projection"]', '0', 7, 0, 0, 1459479921, 1459479921, 36347314, 'http://stackoverflow.com/questions/36347314/plot-decision-boundary-and-projected-line', 'Plot decision boundary and projected line', '<p>I have Linear Discriminant Analysis.It is easy to implement but no source code tells how to plot the decision boundary between the two classes <strong>x1 and x2</strong> in order to classify them. The same code worked with the comment data, but when I put my real data, it didn''t projected and plot the line between the two vectors x1 and x2. I have problem on how to scale and project the line into my data x1 and x2. My projected line looks not good at all. Could you assist me please. Thank you in advance. \n<a href="http://www.csd.uwo.ca/~olga/Courses/CS434a_541a/Lecture8.pdf" rel="nofollow">Here is how I learned LDA for two classes</a></p>\n\n<pre><code>% x1=[1 2;2 3;3 3;4 5;5 5]  \n% x2=[1 0;2 1;3 1;3 2;5 3;6 5]\nx1=[239 0.72;324.6 0.83;331.8 0.95;334.3 0.83;259.7 0.89;212.3 0.88;204.7 0.65;253.86 0.75;258.94 0.85]    \nx2=[329.66, 0.95;469.68, 1.46;459.74,1.11; 293.2 0.64;297.88 0.98;267.9 0.82;374.1 1.29;333.62 0.74]\n\nm1 = mean(x1); \nm2 = mean(x2); \nm = m1 + m2; \nd1=x1-repmat(m1,9,1);\nd2=x2-repmat(m2,8,1);\nc = 0.5.*m; \nSw1 = d1''*d1;\nSw2 = d2''*d2;\nSw = Sw1 + Sw2; \ninvSw = inv(Sw);\nw= invSw*(m1-m2)''\n\nscatter(x1(:,1), x1(:,2), 10, ''ro'');\n hold on;\n scatter(x2(:,1), x2(:,2), 10,''bo'');\n %This makes the line not plotted as it should draw a big line all the way the graph. \n quiver(c(1,1), c(1,2), 1, -w(1,1)/w(2,1));\n quiver(c(1,1), c(1,2), -1, w(1,1)/w(2,1));\n\n auxw= w/norm(w);\n\nplot([0 auxw(1)], [0 auxw(2)]) \n hold off;\n figure; \n y1 = x1*w; \n y2 = x2*w; \n\n hist([y1'' y2''])\n</code></pre>\n', NULL, NULL, NULL, '2016-04-28', '2016-04-28'),
('["python","python-3.x","numpy","linear-algebra","equation-solving"]', '1', 64, 2, -1, 1459511075, 1459508921, 36354807, 'http://stackoverflow.com/questions/36354807/solving-linear-equations-w-three-variables-using-numpy', 'Solving linear equations w. three variables using numpy', '<p>I''m currently in need of a class, which must be able to display and solve an equation system like this one:</p>\n\n<pre><code>| 2x-4y+4z=8  |\n| 34x+3y-z=30 |\n| x+y+z=108   |\n</code></pre>\n\n<p>I thought it would be a good idea to write a class to transform the left-side things of the eqation system into a matrix-like object, here is the self-made-matrix for this system:</p>\n\n<pre><code>/2  -4  4\\\n|34 3  -1|\n\\1  1   1/\n</code></pre>\n\n<p>I have written this currently:</p>\n\n<pre><code>class mymatrix(object):\n    def __init__(self):\n        o11 = None\n        o12 = None\n        o12 = None\n        o21 = None\n        o22 = None\n        o23 = None\n        o31 = None\n        o32 = None\n        o33 = None\n\n    def set(row, column, value):\n        string = ''o''+str(row)+str(column)+'' = ''+str(value)\n        exec(string)\n\n    def solve(self, listwithrightsidethings):\n        #Here I want to solve the system. This code should read  the three    \n        #values out of the list and solves the system It should return the\n        #values for x, y and z in a tuple: (x, y, z)\n        pass\n</code></pre>\n\n<p>I searched a module to solve linear algebra pronlems, and I found numpy. I''ve searched in the manual but didn''t find quite my solution of my problem</p>\n\n<p>How can I write the <code>solve</code> functoin?</p>\n\n<p>Edit:</p>\n\n<p>python should interprete it like this</p>\n\n<pre><code>/o11, o21, o31\\   123\n|o21, o22, o32| = 456\n\\o31, o32, o33/   789\n</code></pre>\n\n<p>Edit: I want to solve it w exactly 3 vars, and return it as a <strong>tuple</strong></p>\n', NULL, NULL, NULL, '2016-04-28', '2016-04-28'),
('["algorithm","matlab","matrix","linear-algebra"]', '0', 34, 0, 1, 1459643296, 1459629423, 36378432, 'http://stackoverflow.com/questions/36378432/optimized-distance-calculation-for-data-cube', 'Optimized Distance Calculation for Data Cube', '<p>Is there an optimized solution for calculating a distance matrix for the distances between slices in a cube? For example, I have a data cube <code>C</code> with dimensions n&times;m&times;t. I want the <code>i</code>-th, <code>j</code>-th index of my distance matrix <code>D</code> to be equal to </p>\n\n<pre><code>D(i,j) = norm(C(:,:,i)-C(:,:,j))\n</code></pre>\n\n<p>And I''d like to do this non-iteratively. </p>\n', NULL, NULL, NULL, '2016-04-28', '2016-04-28'),
('["python","numpy","linear-algebra","eigenvalue","eigenvector"]', '1', 37, 2, 1, 1459753584, 1459717265, 36391125, 'http://stackoverflow.com/questions/36391125/numpy-modal-matrix-and-diagonal-eigenvalues', 'Numpy - Modal matrix and diagonal Eigenvalues', '<p>I wrote a simple Linear Algebra code in Python Numpy to calculate the Diagonal of EigenValues by calculating $M^{-1}.A.M$ (M is the Modal Matrix) and it''s working strange.</p>\n\n<p>Here''s the Code :</p>\n\n<pre><code>import numpy as np\n\narray = np.arange(16)\narray = array.reshape(4, -1)\nprint(array)\n\n[[ 0  1  2  3]\n [ 4  5  6  7]\n [ 8  9 10 11]\n [12 13 14 15]]\n\neigenvalues, eigenvectors = np.linalg.eig(array)\n\nprint eigenvalues\n[  3.24642492e+01  -2.46424920e+00   1.92979794e-15  -4.09576009e-16]\n\nprint eigenvectors\n[[-0.11417645 -0.7327781   0.54500164  0.00135151]\n [-0.3300046  -0.28974835 -0.68602671  0.40644504]\n [-0.54583275  0.15328139 -0.2629515  -0.8169446 ]\n [-0.76166089  0.59631113  0.40397657  0.40914805]]\n\ninverseEigenVectors = np.linalg.inv(eigenvectors) #M^(-1)\ndiagonal= inverseEigenVectors.dot(array).dot(eigenvectors) #M^(-1).A.M\n\nprint(diagonal)\n[[  3.24642492e+01  -1.06581410e-14   5.32907052e-15   0.00000000e+00]\n [  7.54951657e-15  -2.46424920e+00  -1.72084569e-15  -2.22044605e-16]\n [ -2.80737213e-15   1.46768503e-15   2.33547852e-16   7.25592561e-16]\n [ -6.22319863e-15  -9.69656080e-16  -1.38050658e-30   1.97215226e-31]]\n</code></pre>\n\n<p>the final ''diagonal'' matrix should be a diagonal matrix with EigenValues on the main diagonal and zeros elsewhere. but it''s not... the two first main diagonal values ARE eigenvalues but the two second aren''t (although just like the two second eigenvalues, they are nearly zero).</p>\n\n<p>and by the way a number like $-1.06581410e-14$ is literally zero so how can I make numpy show them as zero?</p>\n\n<p>What am I doing wrong?</p>\n\n<p>Thanks...</p>\n', NULL, NULL, NULL, '2016-04-28', '2016-04-28'),
('["python","numpy","matrix","linear-algebra","determinants"]', '1', 81, 3, 3, 1459752664, 1459749800, 36395509, 'http://stackoverflow.com/questions/36395509/python-numpy-treat-really-small-numbers-as-zero', 'Python Numpy - Treat really small numbers as zero', '<p>I want to calculate the Determinant of a Singular Matrix (which has a 0 determinant) with Numpy and when I print the determinant it shows a really small number (which is nearly zero = -7.09974814699e-30) but not zero itself...</p>\n\n<p>when I try to print the determinant either with %s, %d or %f, sometimes it''s zero, sometimes -0 and sometimes -7.09974814699e-30 .</p>\n\n<p>Here''s the Code :</p>\n\n<pre><code>import numpy as np\n\narray = np.arange(16)\narray = array.reshape(4, -1)\ndeterminant = np.linalg.det(array)\n\nprint("Determinant is %s" % determinant)\nprint("Determinant is %d" % determinant)\nprint("Determinant is %f" % determinant)\n\nDeterminant is -7.09974814699e-30\nDeterminant is 0\nDeterminant is -0.000000\n</code></pre>\n\n<p>How can I make Numpy treat really small numbers such as -7.09974814699e-30 as zero and show zero to me. I also asked <a href="https://stackoverflow.com/questions/36391125/numpy-modal-matrix-and-diagonal-eigenvalues">this question</a> before, if you take a look at the matrix you see that it''s filled with really small numbers but not zero while it should be a diagonal matrix with numbers on the diagonal and zeros elsewhere...</p>\n\n<p>Thank you...</p>\n', NULL, NULL, NULL, '2016-04-28', '2016-04-28'),
('["matlab","octave","linear-algebra"]', '1', 29, 1, 0, 1459776027, 1459772778, 36402622, 'http://stackoverflow.com/questions/36402622/octave-access-value-from-a-matrix-by-passing-indices-in-a-vector', 'Octave: Access value from a matrix by passing indices in a vector?', '<p>I need to access/edit values in an <code>n</code> dimensional matrix <code>M</code>, by passing a vector <code>V</code>, containing indices.</p>\n\n<p>let<br>\n<code>M = [ 1,2,3;\n       4,5,6;\n       7,8,9;];</code> </p>\n\n<p>index vectors be</p>\n\n<p><code>V1=[2,1];\n V2=[1,2];</code></p>\n\n<p>now,  <code>M(V1)</code> should give <code>4</code> <br> \nand  <code>M(V2)</code> should give <code>2</code>;</p>\n\n<p>problem is <code>n</code> is not fixed and I don''t want do looping to access values like <code>M(idx_1,idx_2,...idx_n)</code></p>\n', NULL, NULL, NULL, '2016-04-28', '2016-04-28'),
('["r","linear-algebra"]', '0', 11, 1, -1, 1459783730, 1459783265, 36406629, 'http://stackoverflow.com/questions/36406629/is-there-a-way-to-find-the-row-column-spaces-of-a-matrix-in-r', 'Is there a way to find the Row/Column spaces of a matrix in R?', '<p>I was posed this question by a co-worker and the answer is expected of me. Being quite new to R, as well as only being halfway through my first linear algebra course, hours of searching did not yield an answer. Any help here would be much appreciated!</p>\n\n<p>I understand this question is fairly vague and not detailed, but that is exactly how it was posed to me. I will try to add any details if asked.</p>\n\n<p>This is also my first question on here, so I apologize if I am not properly posing a question. Feel free to critique me, I am here to learn.</p>\n', NULL, NULL, NULL, '2016-04-28', '2016-04-28'),
('["python","scipy","linear-algebra"]', '0', 25, 0, 1, 1459888308, 1459888308, 36436478, 'http://stackoverflow.com/questions/36436478/scipy-linearoperator-on-a-matrix', 'Scipy LinearOperator on a matrix', '<p>I have a linear function <code>A</code> that whose input and output is <code>(m,n)</code>numpy array. I want to use CG or GMRES to solve a system <code>A(x) = b</code>. Is there any way I can define scipy <code>LinearOperator</code> without reshaping the input and output inside my function <code>A</code>?</p>\n\n<p>Example:</p>\n\n<pre><code>import numpy as np\nimport scipy.sparse.linalg as linalg\n\na = np.array( [ [1,2] , [3,4] ] )\ndef A(v):\n    return a * v\n\n# I want to do this but this fails. Any other\n# solution that doesn''t involve reshaping?\nlin_op = linalg.LinearOperator( ((2,2),(2,2)), matvec=A )\n</code></pre>\n', NULL, NULL, NULL, '2016-04-28', '2016-04-28'),
('["python","linear-algebra","covariance","pca","variance"]', '1', 28, 1, 0, 1459978640, 1459907447, 36440064, 'http://stackoverflow.com/questions/36440064/pca-same-explained-variance-ratio-for-different-number-of-components', 'PCA : same explained variance ratio for different number of components', '<p>I''m trying to understand PCA. I have a 3-dimensional dataset, I built two PCA models, one with 2 components, and the other with 3 components. However, I don''t understand why the explained variances ratio for both PCA models is the same.</p>\n\n<pre><code>Model with 2 components: [ 0.60792494  0.31234679]\nModel with 3 components: [ 0.60792494  0.31234679  0.07972828]\n</code></pre>\n', NULL, NULL, NULL, '2016-04-28', '2016-04-28'),
('["c++","matrix","linear-algebra","eigen"]', '1', 58, 1, 1, 1459930049, 1459922408, 36442720, 'http://stackoverflow.com/questions/36442720/solving-a-tridiagonal-matrix-using-eigen-package-in-c', 'Solving a Tridiagonal Matrix using Eigen package in C++', '<p>At present I have a system <strong>Ax</strong> = <strong>b</strong> such that <strong>A</strong> is a tridiagonal matrix. Using Eigen, I can already solve this system using the line:</p>\n\n<p>x = A.colPivHouseholderQr().solve(b);</p>\n\n<p>However, since <strong>A</strong> is a tridiagonal matrix this works rather slowly compared to say in MATLAB, since the program is mostly likely computing the solution for all values rather than just on the three diagonals. Can Eigen solve this system faster? This is probably quite a dumb questions but I''m fairly new to C++ and I only started using Eigen a few days ago so there''s a lot to take in at the moment! Thanks in advance.</p>\n', NULL, NULL, NULL, '2016-04-28', '2016-04-28'),
('["c++","arrays","matrix","linear-algebra","alglib"]', '0', 23, 0, 0, 1459970426, 1459950941, 36453304, 'http://stackoverflow.com/questions/36453304/how-can-i-create-an-array-of-matrices-in-with-for-alglib', 'How can I create an array of matrices in/with/for alglib', '<p>I''m trying to make an array of 2d matrices to calculate the eigenvalues with the Alglib library in C++, but I can''t find how I can make an array of matrices (if this is possible) to calculate their eigenvalues. I know how to calculate the eigenvalues and eigenvector for 1 matrix, but for several of them, at the same time, I don''t know. Can anyone help me?</p>\n', NULL, NULL, NULL, '2016-04-28', '2016-04-28'),
('["opengl","graphics","3d","linear-algebra"]', '0', 39, 1, 0, 1460019442, 1459977209, 36462460, 'http://stackoverflow.com/questions/36462460/opengl-screen-space-translation-of-perspective-camera-view', 'OpenGL screen-space translation of perspective camera view', '<p>I am using a perspective projection camera in OpenGL with an eye-target-up approach along the lines of <code>gluLookAt()</code></p>\n\n<p>I would like to move the entire 3d view to a different location within the 2d window, as shown in the image below:</p>\n\n<p><a href="http://i.stack.imgur.com/zYR44.png" rel="nofollow"><img src="http://i.stack.imgur.com/zYR44.png" alt="enter image description here"></a></p>\n\n<p>I know this can be done with <code>glViewport()</code>, but I would ultimately like to be able to rotate the 3d view in addition to translating it, which I understand won''t work with a glViewport approach.</p>\n\n<p>I also understand that taking a non-glViewport approach will require the additional step of stenciling. I''ll leave that step for later.</p>\n\n<p>For now, I''m hoping to simply translate the 3d view as shown in the image above (ignoring the stenciling issue).</p>\n\n<p>It seems like translating the projection matrix is the correct approach, however the translation extent is not what I expect. Perhaps I need to scale the parameter I''m using? In any case, I''m hoping someone can explain how to (more-or-less) simulate a translatable/rotatable glViewport for a 3d perspective view.</p>\n\n<p>Thanks!</p>\n', NULL, NULL, NULL, '2016-04-28', '2016-04-28'),
('["python","numpy","scipy","linear-algebra","sparse-matrix"]', '1', 50, 3, 2, 1460255898, 1460130585, 36504001, 'http://stackoverflow.com/questions/36504001/creating-a-sparse-matrix-from-lists-of-sub-matrices-python', 'Creating a sparse matrix from lists of sub matrices (Python)', '<p>This is my first SO question ever. Let me know if I could have asked it better :)</p>\n\n<p>I am trying to find a way to splice together lists of sparse matrices into a larger block matrix. </p>\n\n<p>I have python code that generates lists of square sparse matrices, matrix by matrix. In pseudocode:</p>\n\n<pre><code>Lx = [Lx1, Lx1, ... Lxn]\nLy = [Ly1, Ly2, ... Lyn]\nLz = [Lz1, Lz2, ... Lzn]   \n</code></pre>\n\n<p>Since each individual Lx1, Lx2 etc. matrix is computed sequentially, they are appended to a list--I could not find a way to populate an array-like object "on the fly".</p>\n\n<p>I am optimizing for speed, and the bottleneck features a computation of Cartesian products item-by-item, similar to the pseudocode:</p>\n\n<pre><code>M += J[i,j] * [ Lxi *Lxj + Lyi*Lyj + Lzi*Lzj ] \n</code></pre>\n\n<p>for all combinations of 0 &lt;= i, j &lt;= n. (J is an n-dimensional square matrix of numbers).</p>\n\n<p>It seems that vectorizing this by computing all the Cartesian products in one step via (pseudocode):</p>\n\n<pre><code>L = [ [Lx1, Lx2, ...Lxn],\n      [Ly1, Ly2, ...Lyn],\n      [Lz1, Lz2, ...Lzn] ]\nproduct = L.T * L\n</code></pre>\n\n<p>would be faster. However, options such as np.bmat, np.vstack, np.hstack seem to require arrays as inputs, and I have lists instead. </p>\n\n<p>Is there a way to efficiently splice the three lists of matrices together into a block? Or, is there a way to generate an array of sparse matrices one element at a time and then np.vstack them together?</p>\n\n<p>Reference: Similar MATLAB code, used to compute the Hamiltonian matrix for n-spin NMR simulation, can be found here:</p>\n\n<p><a href="http://spindynamics.org/Spin-Dynamics---Part-II---Lecture-06.php" rel="nofollow">http://spindynamics.org/Spin-Dynamics---Part-II---Lecture-06.php</a></p>\n', NULL, NULL, NULL, '2016-04-28', '2016-04-28'),
('["algorithm","optimization","matrix","linear-algebra","linear-programming"]', '0', 32, 0, -1, 1460218789, 1460218789, 36519490, 'http://stackoverflow.com/questions/36519490/find-a-dual-from-a-primal-in-linear-programming', 'Find a dual from a primal in Linear Programming', '<p>I''m working with a general LP problem, where I try to formulate the dual problem from the primal: <br>\n<a href="http://i.stack.imgur.com/LZVIH.png" rel="nofollow">The primal problem</a>\n <br><br></p>\n\n<p>I have converted the general LP problem to its standard form as shown below:\n<a href="http://i.stack.imgur.com/74gFV.png" rel="nofollow">The primal in standard form</a></p>\n\n<p>But what I don''t understand is how the A vectors in the primal should be represented in its dual problem. Can I just do matrix transponent on A like I do on a 1-D matrix?</p>\n\n<p>Thanks for any help.</p>\n', NULL, NULL, NULL, '2016-04-28', '2016-04-28'),
('["c++","linear-algebra","eigen3"]', '1', 31, 1, 1, 1460374722, 1460226017, 36520854, 'http://stackoverflow.com/questions/36520854/how-to-compute-the-symmetric-of-a-point-high-dimension-space-with-respect-to-a', 'How to compute the symmetric of a point (high dimension space) with respect to a hyperplane formed by a set of points?', '<p>I''m using C++ and I want to calculate the symmetric of a point with respect to a hyperplane. I''m in a <strong>dimension given at execution time</strong>.</p>\n\n<p>I have the points in the hyperplane. So I calculated the normal vector by solving a set of linear equations. Then to get the hyperplane (with the normal and a point), the projection of the first point and finally the symmetric.</p>\n\n<p>I tried using the <code>eigen3</code> library but it seems it needs the dimension to be given at compile time.</p>\n\n<p>Any idea to solve the problem with this library (or any other one) or a short-cut method are welcome.</p>\n\n<p>Thank you in advance.</p>\n', NULL, NULL, NULL, '2016-04-28', '2016-04-28');
INSERT INTO `so_questions` (`tags`, `is_answered`, `view_count`, `answer_count`, `score`, `last_activity_date`, `creation_date`, `question_id`, `link`, `title`, `body`, `has_more`, `quota_max`, `quota_remaining`, `createdAt`, `updatedAt`) VALUES
('["optimization","linear-algebra","theano","theano.scan"]', '0', 19, 0, 0, 1460944637, 1460244110, 36523898, 'http://stackoverflow.com/questions/36523898/when-to-use-theano-scan-based-on-a-minimal-example', 'When to use theano.scan? (Based on a minimal example)', '<p>Theano.scan is a looping construct that can be faster than a python for-loop, but slower than an equivalent "vectorized" approach.  <strong>When is theano.scan "better"</strong>?  "Better" primarily means faster, but is intended to leave other factors open for comment.  To focus the question, let''s consider this minimal problem.</p>\n\n<p><strong>Problem</strong>: Given the <em>m</em>-by-<em>k</em> matrix <strong>A</strong>, and a <em>k</em>-by-<em>m</em> matrix <strong>B</strong>, compute the vector <em>c</em>, whose <em>i</em>th element is the dot product of row <em>i</em> of <strong>A</strong> with column <em>i</em> of <strong>B</strong>.</p>\n\n<p><strong>Solution using Scan</strong>:<br>\nWe''ll pass in <strong>A</strong> and the transpose of <strong>B</strong>, as sequences, to scan, which will then pair up the corresponding rows of <strong>A</strong> and columns of <strong>B</strong> to be operated on.  We tell it to take the dot product of each pair, giving the desired result.</p>\n\n<pre><code>from theano import tensor, scan, function\nA = tensor.dmatrix(''A'')\nB = tensor.dmatrix(''B'')\nC, updates = theano.scan(\n    fn=lambda x,y: T.dot(x,y),\n    outputs_info=None,\n    sequences=[A, B.T]   # Transpose B: rows of A get paired with cols of B\n)\n\nf = function([A,B], C)\n</code></pre>\n\n<p><strong>"Vectorized" Solution</strong><br>\nHere, we''ll do ordinary matrix multiplication.  The <em>i</em>,<em>j</em>th element in the result represents the dot product of the <em>i</em>th row of <strong>A</strong> with the jth row of <strong>B</strong>, so we can just take the elements on the main diagonal to get our result.</p>\n\n<pre><code>from theano import tensor, scan, function\nA = tensor.dmatrix(''A'')\nB = tensor.dmatrix(''B'')\nC = tensor.dot(A,B).diagonal()\n\nf = function([A,B], C)\n</code></pre>\n\n<p><strong>Questions</strong></p>\n\n<ul>\n<li>So, which is faster?  </li>\n<li>Notice how the matrix multiplication in the vectorized solution implies <em>m</em><sup>2</sup> dot products, but the result only uses <em>m</em> of them -- does theano optimize <em>f</em> so that only the <em>m</em> needed dot products are actually computed?</li>\n</ul>\n', NULL, NULL, NULL, '2016-04-28', '2016-04-28'),
('["c","matrix","linear-algebra"]', '1', 43, 2, 3, 1460267188, 1460261572, 36525701, 'http://stackoverflow.com/questions/36525701/efficient-way-to-find-rows-with-same-elements-in-a-3d-matrix-in-c', 'Efficient way to find rows with same elements in a 3D matrix in C', '<p>I have a 3D matrix <code>mat[100][100][100]</code>. What is the efficient way to find a row with same elements that appears in <code>mat[0][][], mat[1][][],....,mat[99][][]</code>? \nA simple approach would be comparing each row of <code>mat[0][][]</code> to all rows of the remaining 99 matrices, but it wouldn''t be very efficient(I guess). Is there a better way to do it?   </p>\n', NULL, NULL, NULL, '2016-04-28', '2016-04-28'),
('["matlab","matrix","linear-algebra","eigenvalue"]', '1', 24, 1, 0, 1460391295, 1460383944, 36551182, 'http://stackoverflow.com/questions/36551182/how-can-i-find-the-joint-eigenvalues-of-two-matrices-in-matlab', 'How can I find the joint eigenvalues of two matrices in MATLAB?', '<p>If the joint eigenvalues of matrices <strong>A</strong> and <strong>B</strong> are defined as the roots of the equation \ndet(lambda * <strong>A</strong> - <strong>B</strong>) = 0,\nhow can I solve this in MATLAB? </p>\n\n<p>In particular, I am not sure how exactly lambda is defined - it obviously needs to be a matrix or vector, as otherwise there would only be one joint eigenvalue. Also, I am not sure if there is any in-built function, or if, say, fzero for finding the roots of nonlinear functions needs to be used.</p>\n', NULL, NULL, NULL, '2016-04-28', '2016-04-28'),
('["r","optimization","linear-algebra","rcpp"]', '1', 24, 1, 0, 1460464944, 1460464700, 36573523, 'http://stackoverflow.com/questions/36573523/optimisation-of-backsolve-base-function', 'Optimisation of backsolve base function', '<p>I am wondering if there could be any possible was to optimize the base package function backsolve ? for example using Rccp. I have googled a bit but couldn''t find any response:</p>\n\n<ol>\n<li><p>is there an alternative package doing better ?</p></li>\n<li><p>if no is it worth striving to do it by myself ? because maybe the base function is already well optimised</p></li>\n</ol>\n', NULL, NULL, NULL, '2016-04-28', '2016-04-28'),
('["c++","arrays","linear-algebra"]', '1', 32, 1, -4, 1460480150, 1460479515, 36579365, 'http://stackoverflow.com/questions/36579365/how-do-i-know-number-of-cells-between-two-points-in-array', 'How do i know number of cells between two points in array?', '<p>i have 2D array and give tow points p1(x1,y1) and p2(x2,y2) , is that any way to know number of cells between them ?</p>\n', NULL, NULL, NULL, '2016-04-28', '2016-04-28'),
('["matrix","linear-algebra","linear","diagonal"]', '0', 19, 0, 0, 1460566054, 1460566054, 36604780, 'http://stackoverflow.com/questions/36604780/solver-for-a-nine-diagonal-linear-system', 'Solver for a nine diagonal linear system', '<p>Is there any solver for a 9-diagonal system of equations with periodic boundaries?</p>\n\n<p>The kind of matrices I am referring look like this (white stands for non-zero entries):</p>\n\n<p><a href="http://i.stack.imgur.com/oEkRp.png" rel="nofollow"><img src="http://i.stack.imgur.com/oEkRp.png" alt="enter image description here"></a></p>\n\n<p>I can not find a better available approach than calling a sparse solver.</p>\n', NULL, NULL, NULL, '2016-04-28', '2016-04-28'),
('["ios","iphone","linear-algebra","armadillo"]', '0', 20, 0, 0, 1460576955, 1460575444, 36607763, 'http://stackoverflow.com/questions/36607763/incorporating-armadillo-library-in-an-ios-application', 'Incorporating Armadillo library in an iOS application', '<p>I am trying to incorporate Armadillo linear-algebra library in an iOS application. Upon building, I am getting the following error:</p>\n\n<blockquote>\n  <p>ld: building for iOS Simulator, but linking against dylib built for\n  MacOSX file ''/usr/local/lib/libarmadillo.dylib'' for architecture\n  x86_64 clang: error: linker command failed with exit code 1 (use -v to\n  see invocation)</p>\n</blockquote>\n\n<p>I understand that when I built Armadillo library (ver 6.5) it did not built for iOS. I have seen tips on creating a fat library but have been unable to modify Armadillo makefile to do so. FYI, I am newbie when it comes to Linux/iOS/xCode development environment.</p>\n\n<p>Any suggestion is much appreciated.  </p>\n', NULL, NULL, NULL, '2016-04-28', '2016-04-28'),
('["algorithm","linear-algebra","computational-geometry","graph-algorithm","trigonometry"]', '0', 17, 1, 0, 1460682067, 1460656358, 36630482, 'http://stackoverflow.com/questions/36630482/how-to-follow-the-path-of-a-super-ellipse-with-2-linked-axis', 'How to Follow the Path of a Super Ellipse with 2 Linked Axis', '<p>I have two axis linked together ; Axis A, and Axis B. Axis B is attached to the end of Axis A and so its point of origin can vary with the angle of Axis A . Attached to Axis B is a Circle whose Diameter is 10 (and can become smaller). I need to move the edge point of the circle to intersect a Super-Ellipse at each of 38 Cartesian points x,y. So the end point of my axis B - center of the circle should follow the same basic path as the 38 points of the super ellipse - radius of circle. Once I have these points - I will need to determine the position of Axis A x_2,y_2 and angle (or more appropriately just the distance from 0 degree angle to reach the required angle to position x_2,y_2. I then need to position Axis B with relation to Axis A in order to have Axis B X_3,Y_3 match the following of the Super-Ellipse where the center of the circle is supposed to be.</p>\n\n<p>I have a drawing attached and a plot in Excel where I am off as you can see the bow tie is not what I should have. I have also included the points to the super ellipse along with some quick points on the graph. I am not a math major - I am willing to learn if you post the name of an equation - so far I have learned about carnot, parametric equation for circles and formulas for parabolas - but I am still having trouble.</p>\n\n<p><a href="http://i.stack.imgur.com/Uc92e.png" rel="nofollow"><img src="http://i.stack.imgur.com/Uc92e.png" alt="Graphical Representation of the Problem"></a>\n<a href="http://i.stack.imgur.com/DDKwN.png" rel="nofollow"><img src="http://i.stack.imgur.com/DDKwN.png" alt="Excel Layout of plotting points - the inner path is not properly followed."></a></p>\n\n<pre><code>Axis A Radius 13" image is 90 degree rotation\nX_Sub1 , Y_Sub1 \n-6.5   , 5\n\nAxis B Radius 9" image is 180 degree rotation\nX_Sub2 , Y_Sub2 \n 6.5   , 5\n\nCircle Diameter 10" \nCircle Radius 5" \n\nSuper Ellipse \n@ 12"width\n@ 8.75" Deep Vertex -8.75\n\nPoints Along the Super Ellipse.\n0.0000,  0.0000\n0.2188, -0.6250\n0.2188, -1.2500\n0.2433, -1.8750\n0.3290, -2.5000\n0.4753, -3.1073\n0.6804, -3.7091\n0.9424, -4.2990\n1.2585, -4.8712\n1.6255, -5.4197\n2.0397, -5.9388\n2.4967, -6.4233\n2.9920, -6.8682\n3.5203, -7.2889\n4.0764, -7.7213\n4.6544, -8.0500\n5.2285, -8.3553\n5.7525, -8.5000\n6.2188, -8.5516\n6.6851, -8.5000\n7.1891, -8.3553\n7.7832, -8.0500\n8.3612, -7.7213\n8.9173, -7.2889\n9.4456, -6.8682\n9.9409, -6.4233\n10.3979,-5.9388\n10.8121,-5.4197\n11.1791,-4.8712\n11.4952,-4.2990\n11.7572,-3.7091\n11.9623,-3.1073\n12.1086,-2.5000\n12.1943,-1.8750\n12.2188,-1.2500\n12.2188,-0.6250\n12.4376, 0.0000\n</code></pre>\n', NULL, NULL, NULL, '2016-04-28', '2016-04-28'),
('["c++","linear-algebra"]', '1', 55, 1, -1, 1460668616, 1460666821, 36633667, 'http://stackoverflow.com/questions/36633667/calculate-angle-with-xyz-rotation-and-my-enemy-his-xyz-rotation-linear-alge', 'Calculate angle with XYZ + rotation and my enemy his XYZ + rotation [Linear Algebra]', '<p>Tally-ho chaps,</p>\n\n<p>This question considers the art of linear algebra a place in math where I fall short to solve this. So I am hoping you guys could help me out :D.</p>\n\n<p>I am trying to create a singleplayer autokicker cheat for a game called mount and blade. The goal of this autokicker is to always successfully kick the player using the power of math. I managed to achieve a lot of things thanks to the help of the internet (aimbot,esp,...) but now I am kinda stuck since I don''t know enough linear algebra to get angles etc. These are the things I have </p>\n\n<ul>\n<li><p>My XYZ (player position)</p></li>\n<li><p>Rotation starting from coordinate (0,0) radians converted to degrees (-180;180)</p></li>\n<li><p>Enemy XYZ and rotation</p></li>\n</ul>\n\n<p>A player can successfully kick another player if the distance is less than \n1 float and the player is in front of the other player. Hence why I need to calculate the angle between the direction I am looking and the enemy his XYZ. I will draw in paint what <a href="http://i.stack.imgur.com/KuYXp.png" rel="nofollow">I want to achieve.</a></p>\n\n<p><a href="http://i.stack.imgur.com/KuYXp.png" rel="nofollow"><img src="http://i.stack.imgur.com/KuYXp.png" alt="enter image description here"></a>\n<a href="http://i.stack.imgur.com/0SVfW.png" rel="nofollow"><img src="http://i.stack.imgur.com/0SVfW.png" alt="http://i.stack.imgur.com/0SVfW.png"></a></p>\n\n<p><a href="http://i.stack.imgur.com/0SVfW.png" rel="nofollow">These are the values displayed in game</a> first is calculated distance next is enemy rotation and last is my rotation. I think rotation is done on the 0,0 spot</p>\n\n<p>Any help is appreciated and awarded with a massive thumbs up :D! </p>\n\n<pre><code>float Distance(D3DXVECTOR3 vector1, D3DXVECTOR3 vector2)\n{\n    return sqrt(pow((vector1.x - vector2.x), 2) + pow((vector1.y - vector2.y), 2) + pow((vector1.z - vector1.z), 2));\n}\n\nbool AutoKick()\n{\n    for (size_t i = 0; i &lt; cPlayerBase.size(); i++)\n    {\n        float DistanceToLocalPlayer = Distance(cPlayerBase[i]-&gt;vec, mainPlayer.vec); // vec is X Y Z\n        float number = Rad2Deg(atan2(cPlayerBase[i]-&gt;vecRotation[1], cPlayerBase[i]-&gt;vecRotation[0])); // X Y rotation\n\n        if(cPlayerBase[i]-&gt;address == mainPlayer.pointer ) \n        std::cout &lt;&lt; "My degree -- " &lt;&lt; number;\n        if (DistanceToLocalPlayer != 0.0f)\n        {\n            std::cout &lt;&lt; "Enemy Distance -- " &lt;&lt; DistanceToLocalPlayer &lt;&lt; "Enemy degree -- " &lt;&lt; number;\n        }\n        std::cout &lt;&lt; std::endl;\n    }\n\n    return true;\n}\n</code></pre>\n', NULL, NULL, NULL, '2016-04-28', '2016-04-28'),
('["matlab","linear-algebra","projection","perspectivecamera"]', '0', 18, 0, 0, 1460724525, 1460723036, 36647100, 'http://stackoverflow.com/questions/36647100/how-to-correctly-project-world-coordinates-to-image-coordinates-with-camera-matr', 'How to correctly project world coordinates to image coordinates with camera matrix', '<p>When I try to use the camera matrix as per <a href="https://en.wikipedia.org/wiki/Camera_matrix" rel="nofollow">wikipedia</a> somehow I dont get the value 1 in the homogeneous dimension of pixel location. I cant figure out what I am doing wrong. Searching on stackoverflow resulted in higher level programming questions, I didnt find problems regarding the camera matrix and the multiplication with real world coordinates.</p>\n\n<p><strong><em>First I make up some world coordinates</em></strong></p>\n\n<pre><code>%number of world grid locations along x1 and x2\nresproj = 4096;\n\n%projected surface pixel coordinates\n[x1proj,x2proj] = ndgrid([1:resproj], [1:resproj]);\n%origin at center\nx1proj = x1proj - resproj/2; y2proj = y2proj - resproj/2;\n\n%distance map for projected image\nx3proj = ones(size(y1proj));\nx3proj(1:end/2,1:end/2) = 0;%q1,1\nx3proj(1:end/4,1:end/4) = 1;%q1,1 sub1,1\nx3proj(end/2:end,1:end/2) = y1proj(end/2:end,1:end/2)/resproj;%q1,2\nx3proj(1:end/2,end/2:end) = y2proj(1:end/2,end/2:end)/resproj;%q2,1\nx3proj(end/2:end,end/2:end) = sqrt( (y1proj(end/2:end,end/2:end)/resproj).^2 + ...\n                                    (y2proj(end/2:end,end/2:end)/resproj).^2 ); %q2,2\n</code></pre>\n\n<p>So just square with some depth information. Depth looks like this</p>\n\n<pre><code>figure; imshow(x3proj,[])\n</code></pre>\n\n<p><a href="http://i.stack.imgur.com/YUcbW.jpg" rel="nofollow"><img src="http://i.stack.imgur.com/YUcbW.jpg" alt="enter image description here"></a></p>\n\n<p><strong><em>Then I make up some camera</em></strong></p>\n\n<pre><code>%proj focal distance\nfproj = 1/8;\n\n%cameramatrix\nP = zeros(3,4); P(1,1) = fproj; P(2,2) = fproj; P(3,3) = 1;\n</code></pre>\n\n<p><strong><em>Then I project the real world coordinates to camera coordinates</em></strong></p>\n\n<pre><code>xprojall = [x1proj(:)'';x2proj(:)'';x3proj(:)'';ones(size(x1proj(:)''))];\n\nyprojall = P*xprojall;\ny1proj = reshape(yprojall(1,:)'', size(x1proj));\ny2proj = reshape(yprojall(2,:)'', size(x2proj));\ny3proj = reshape(yprojall(3,:)'', size(x3proj));\n</code></pre>\n\n<p>I expect to have a projection of my real world coordinates where there is no depth, however I end up with a depth. </p>\n\n<pre><code>figure; \nsubplot(1,3,1); imshow(y1proj,[]); title(''y1 coordinate''); colorbar\nsubplot(1,3,2); imshow(y2proj,[]); title(''y2 coordinate''); colorbar\nsubplot(1,3,3); imshow(y3proj,[]); title(''y3 coordinate''); colorbar\n</code></pre>\n\n<p><a href="http://i.stack.imgur.com/aqrlg.jpg" rel="nofollow"><img src="http://i.stack.imgur.com/aqrlg.jpg" alt="enter image description here"></a></p>\n\n<p><strong><em>So then I have a problem</em></strong></p>\n\n<p>So the y3 coordinate should be 1 everwhere because that is the image plane where I project it to. I expected a scaling constant at most. Also y1 and y2 I expected to show more differences than just the x1 and x2 gradient. Can anyone see what I mess up?</p>\n', NULL, NULL, NULL, '2016-04-28', '2016-04-28'),
('["c++","arrays","linear-algebra"]', '0', 23, 0, 1, 1460818146, 1460809525, 36664149, 'http://stackoverflow.com/questions/36664149/find-linear-dependent-rows-in-binary-2d-array', 'Find linear dependent rows in binary 2d array', '<p>I''m working on implementing gaussian elimination on ZF^2. \nSo, all elements in the matrix are in range {0,1}; I have implemented gaussian elimination successfully using the <a href="https://www.cs.umd.edu/~gasarch/TOPICS/factoring/fastgauss.pdf" rel="nofollow">fastgauss method</a></p>\n\n<p>But at now I have a problem, because I don''t want to use any library and I want to find all linear dependent rows in an array; can any one help me with suggesting proper algorithms for that? I''m stuck in here, because I want to find the most optimal way to do this.</p>\n', NULL, NULL, NULL, '2016-04-28', '2016-04-28'),
('["matlab","octave","linear-algebra"]', '0', 26, 0, 0, 1460826502, 1460812983, 36664741, 'http://stackoverflow.com/questions/36664741/model-reduction-of-spring-mass-system-in-matlab', 'Model reduction of spring mass system in matlab', '<p>If I have a mass spring system Mx''''+kx=f and want to reduce the model to x=By where B is a real mxp matrix with B orthonormal, how would I go about creating a matlab script to do so? I want to stick with using the first 3 eigenmodes.</p>\n\n<p>I know I can multiply by a projection matrix P=BB'', but I need to use SVD but I am not sure how to use this function in matlab for model reduction.</p>\n', NULL, NULL, NULL, '2016-04-28', '2016-04-28'),
('["math","geometry","linear-algebra","coordinate-systems","coordinate-transformation"]', '1', 82, 2, 1, 1460976602, 1460874082, 36673332, 'http://stackoverflow.com/questions/36673332/how-do-i-transform-between-a-static-and-a-dynamic-coordinate-system', 'how do i transform between a static and a dynamic coordinate system', '<p>i have a setup like this: </p>\n\n<p><a href="http://i.stack.imgur.com/YJI6Q.jpg" rel="nofollow"><img src="http://i.stack.imgur.com/YJI6Q.jpg" alt="enter image description here"></a></p>\n\n<p>2 coordinate systems. (x,y) is the main coordinate system and (x'',y'') is a coordinate system that lives inside (x,y).  The system (x'',y'') is defined by the points x1 or x2 and if i move these 2 points around then (x'',y'') moves accordingly. The origin of (x'',y'') is defined as the middle of the vector going from x1 to x2, and the y'' axis is the normal vector on x1->x2 going through the origin. If i have a point x3 defined in (x'',y'') and i move either of x1 or x2 to make the origin shift place, how do i then move x3 accordingly such that it maintains its position in the new (x'',y'') ?\nAnd how do i make a transformation which always converts a point in (x,y) to a point in (x'',y'') nomatter how x1 and x2 have been set?</p>\n\n<p>I was thinking that if i had more points than just the one i am moving (x1 or x2) i guess i could try to estimate theta, tx, ty of the transformation</p>\n\n<pre><code>[x2'']   [cos(theta) , sin(theta), tx][x2]\n[y2''] = [-sin(theta), cos(theta), ty][y2]\n[ 1 ]   [    0      ,      0    , 1 ][1 ]\n</code></pre>\n\n<p>and just apply that estimated transformation to x3 and i would be good...mmm but i think i would need 3 points in order to estimate theta, tx and ty right? \nI mean i could estimate using some least squares approach...but 3 unknowns requires 3 coordinate sets right?</p>\n\n<p>I tried to implement this and calculate an example. I hope you understand the syntax. Its not really giving me what i expect:</p>\n\n<pre><code>import math\nimport numpy as np\n\nx1=[ 0,10]\nx2=[10,20]\n\nrx = x2[0] - x1[0]\nry = x2[1] - x1[1]\nrlen = math.sqrt(rx*rx+ry*ry)\nc = rx / rlen\ns = ry / rlen\n\n\ndx = - ( x1[0] + x2[0] )/2 # changing the sign to be negative seems to \ndy = - ( x1[1] + x2[1] )/2 # rectify translation. Rotation still is wrong\n\nM = np.array([[c, -s, 0],[s, c, 0],[dx, dy, 1]])\nprint( np.dot(x2 + [1],M) )\n# Yields -&gt; [ 15.92031022  -8.63603897   1.        ] and should yield [5,0,1]\n</code></pre>\n\n<p>Since I am trying to transform the x2 coordinate, should the result then not have the value 0 in the y-component since its located in the x-axis?</p>\n\n<p>Ok, I tried doing the implementation for x3 from dynamic1 to dynamic2 which the check is that x3 should end up with the same coordinate in both d1 and d2. I did that as you suggested, but I do not get the same coordinate in both d1 and d2. Did i misunderstand something?</p>\n\n<pre><code>import math\nimport numpy as np\n\nx1=[ 1,1]\nx2=[ 7,9]\n\nx3=[4,3]\n\nrx = (x2[0] - x1[0])\nry = (x2[1] - x1[1])\nrlen = math.sqrt( rx*rx + ry*ry )\nc = rx / rlen\ns = ry / rlen\n\n\ndx =  ( x1[0] + x2[0] )/2\ndy =  ( x1[1] + x2[1] )/2\n\nM = np.array([[c, -s, 0],[s, c, 0],[-dx*c-dy*s, dx*s-dy*c, 1]])\nMinv = np.array([[c, s, 0],[-s, c, 0],[dx, dy, 1]])\n\n\nx1new=[ 1,1]\nx2new=[ 17,4]\n\nrxnew = (x2new[0] - x1new[0])\nrynew = (x2new[1] - x1new[1])\nrlennew = math.sqrt( rxnew*rxnew + rynew*rynew )\ncnew = rxnew / rlennew\nsnew = rynew / rlennew\n\n\ndxnew =  ( x1new[0] + x2new[0] )/2\ndynew =  ( x1new[1] + x2new[1] )/2\n\nMnew = np.array([[cnew, -snew, 0],[snew, cnew, 0],[-dxnew*cnew-dynew*snew, dxnew*snew-dynew*cnew, 1]])\nMnewinv = np.array([[cnew, snew, 0],[-snew, cnew, 0],[dxnew, dynew, 1]])\n\nM_dyn1_to_dyn2 = np.dot(Minv,Mnew)\n\nprint( np.dot(x3 + [1], M) )\nprint( np.dot(x3 + [1], M_dyn1_to_dyn2))\n#yields these 2 outputs which should be the same:\n[-1.6 -1.2  1. ]\n[-3.53219692  8.29298408  1.        ]\n</code></pre>\n', NULL, NULL, NULL, '2016-04-28', '2016-04-28'),
('["algorithm","matrix","linear-algebra","svd","matrix-decomposition"]', '0', 20, 0, 0, 1460880714, 1460880714, 36674154, 'http://stackoverflow.com/questions/36674154/most-efficient-method-for-computing-singular-value-decomposition-for-an-upper-tr', 'Most efficient method for computing Singular Value Decomposition for an upper triangular matrix?', '<p>There are several methods available for computing SVD of a general matrix. I am interested to know about the best approach which could be used for computing SVD of an upper triangular matrix. Please suggest me an algorithm which could be optimized for this special case of matrices.</p>\n', NULL, NULL, NULL, '2016-04-28', '2016-04-28'),
('["python","numpy","matrix","scipy","linear-algebra"]', '1', 30, 2, 2, 1460909129, 1460903996, 36677940, 'http://stackoverflow.com/questions/36677940/finding-solutions-to-row-reduced-matrix-python', 'Finding solutions to row reduced matrix python', '<p>Suppose I have a reduced Matrix in this form:</p>\n\n<pre><code>   x    y    z    =\n[[2.0, 4.0, 4.0, 4.0], \n [0.0, 2.0, 1.0, 2.0], \n [0.0, 0.0, 1.0, 1.0], \n [0.0, 0.0, 0.0, 0.0]]\n</code></pre>\n\n<p>And I want an array containing the solutions.</p>\n\n<p>In this case I''d want to return</p>\n\n<pre><code>  z    y     x\n[1.0, 0.5, -1.0]\n</code></pre>\n\n<p>We can assume it is a perfect triangle with no free variables.</p>\n\n<p>I was looking at <code>scipy.linalg.solve</code> to solve, but it requires the form <code>Ax=B</code> and I''m not sure how to convert to this form.</p>\n', NULL, NULL, NULL, '2016-04-28', '2016-04-28'),
('["algorithm","math","linear-algebra","check-digit"]', '1', 53, 1, 2, 1461344191, 1461163126, 36747247, 'http://stackoverflow.com/questions/36747247/alternative-base-table-for-damm-algorithm', 'Alternative base table for Damm algorithm', '<p>The Damm algorith is awesome for handling check digits\n<a href="https://en.wikipedia.org/wiki/Damm_algorithm" rel="nofollow">https://en.wikipedia.org/wiki/Damm_algorithm</a></p>\n\n<p>I would like to use it for two different entities of an application. However they should not have the same check digit for the same number.</p>\n\n<p>So i have to use different base tables for each entity. The base table is a totally anti-symmetric quasigroup with n=10\nThe example from Wikipedia:<br>\n--      0   1   2   3   4   5   6   7   8   9<br>\n0   0   3   1   7   5   9   8   6   4   2<br>\n1   7   0   9   2   1   5   4   8   6   3<br>\n2   4   2   0   6   8   7   1   3   5   9<br>\n3   1   7   5   0   9   8   3   4   2   6<br>\n4   6   1   2   3   0   4   5   9   7   8<br>\n5   3   6   7   4   2   0   9   5   8   1<br>\n6   5   8   6   9   7   2   0   1   3   4<br>\n7   8   9   4   5   3   6   2   0   1   7<br>\n8   9   4   3   8   6   1   7   2   0   5<br>\n9   2   5   8   1   4   3   6   7   9   0  </p>\n\n<p>How do i generate a second one, that is different but also of n=10 ?</p>\n', NULL, NULL, NULL, '2016-04-28', '2016-04-28'),
('["c++","multithreading","performance","linear-algebra"]', '1', 44, 1, -2, 1461255556, 1461179633, 36753097, 'http://stackoverflow.com/questions/36753097/need-help-solving-sparse-ax-b', 'Need Help Solving Sparse Ax=b', '<p>I know there is a lot of information out there on this topic, but I''m struggling to find the best solution for my specific problem.</p>\n\n<p>For my problem, A is extremely large (~145k X 145k) and extremely sparse (max of 9 non-zero values per row). It is not positive definite, nor symmetric, and is complex valued (single precision). The sparsity pattern can be visualized by imagining a tridiagonal matrix, and then adding two "tridiagonals" above and below that, N away from the main tridiagonal. This gives 3 sets of 3 non zeros in each row, with sets of 3 separated by N (N is constant for a given matrix A), and centered on the main diagonal. ~5% of rows will not fill all 9 non-zero positions, due to boundary conditions, so these rows will have a subset of the main non-zero pattern.</p>\n\n<p>I need to solve for multiple right hand sides (~1024). I also need to resolve the same system with different numeric values in A, but the same sparsity pattern.  Currently, I''m using SuperLU (single threaded) to factor A to LU and then solving using cusparse (specifically, cusparseCcsrsm_solve). </p>\n\n<p>Is a sparse direct solver using LU factorization the best approach for my problem? Which library would be the fastest for LU factorization? Which would be the fastest for solving with back substitution? </p>\n', NULL, NULL, NULL, '2016-04-28', '2016-04-28'),
('["algorithm","matlab","matrix","linear-algebra","graph-algorithm"]', '0', 43, 2, 1, 1461351601, 1461349038, 36800771, 'http://stackoverflow.com/questions/36800771/matrix-reordering-to-block-diagonal-form', 'Matrix reordering to block diagonal form', '<p>Give a sparse matrix, how to reorder the rows and columns such that it is in block diagonal like form via row and column permutation?</p>\n\n<p>Row and column permutation are not necessarily coupled like reverse Cuthill-McKee ordering:\n<a href="http://www.mathworks.com/help/matlab/ref/symrcm.html?refresh=true" rel="nofollow">http://www.mathworks.com/help/matlab/ref/symrcm.html?refresh=true</a> In short, you can independently perform any row or column permutation. </p>\n\n<p>The overall goal is to cluster all the non zero elements towards diagonal line.</p>\n', NULL, NULL, NULL, '2016-04-28', '2016-04-28'),
('["linear-algebra","matrix-multiplication","cublas"]', '1', 22, 1, 0, 1461774726, 1461350698, 36801241, 'http://stackoverflow.com/questions/36801241/efficiently-multiplying-matrix-with-transpose-using-cublas', 'Efficiently multiplying matrix with transpose using cuBlas', '<p>Is there an efficient way of using cuBlas when multiplying a large dense matrix with its transpose? Specifically, is there any function that makes use of the fact that the resulting matrix is symmetric therefore reducing the number of multiplications by a factor of ~2. </p>\n', NULL, NULL, NULL, '2016-04-28', '2016-04-28'),
('["fortran","linear-algebra","lapack"]', '1', 71, 2, 0, 1461401354, 1461352567, 36801701, 'http://stackoverflow.com/questions/36801701/dgtsv-lapack-not-returning-answer', 'dgtsv - LAPACK not returning answer', '<p>I''m trying to solve a simple tridiagonal system of equations using LAPACK library. The code below explains it all.</p>\n\n<p>I''m getting an array full of zeros (initialized ones), not the correct answer.</p>\n\n<p>I checked the inputs, tried to compile with two compilers and everything seems fine. What is wrong?</p>\n\n<p>The compilation line is:</p>\n\n<pre><code>ifort -L/usr/local/lib/ -llapack -lblas tLapack.f90 -o tlapack  \ngfortran -L/usr/local/lib/ -llapack -lblas tLapack.f90 -o tlapack  \n</code></pre>\n\n<p>the code is:</p>\n\n<pre><code>program lapackT\n\n  implicit none\n\n  ! dgtsv( integer(4) :: N,\n  !        integer(4) :: NRHS,\n  !        real(8)    :: DL[],\n  !        real(8)    :: D [],\n  !        real(8)    :: DU[],\n  !        real(8)    :: B [],\n  !        integer(4) :: LDB ,\n  !        integer(4) :: info )\n\n  ! [A][x] = [b]\n  ! N    - The order of matrix [A] \n  ! NRHS - Number of coluns in [b]\n  ! DL   - Array with the subdiag.\n  ! D    - Main diagonal.\n  ! DU   - Upper Diagonal.\n  ! B    - Answer !!\n  ! LDB  - length of array [B].\n  ! INFO - If = 0 .. Uhul !!.\n\n  real(8), dimension(3) :: mainDiag\n  real(8), dimension(2) :: lowerDiag\n  real(8), dimension(2) :: upperDiag\n  real(8), dimension(3) :: unknow\n  real(8), dimension(3) :: equalty\n\n  integer(4) :: info = 0\n  integer(4) :: i = 0\n\n  integer(4) :: N    = 3\n  integer(4) :: NRHS = 1\n  integer(4) :: LDB  = 3\n\n  mainDiag(1) = 2.0d0\n  mainDiag(2) = 2.0d0\n  mainDiag(3) = 2.0d0\n\n  upperDiag(1) = 3.0d0\n  upperDiag(2) = 3.0d0\n\n  lowerDiag(1) = 1.0d0\n  lowerDiag(2) = 1.0d0\n\n  equalty(1) = 1.0d0\n  equalty(2) = 1.0d0\n  equalty(3) = 1.0d0\n\n  unknow = 0.0d0 ! answer\n\n  call dgtsv(N,NRHS,lowerDiag,mainDiag,upperDiag,equalty,LDB,info)\n\n\n\n  write(*,*) info\n\n  do i = 1,size(unknow)\n    write(*,*) unknow(i)\n  end do\n\n  ! Correct answer: unknow = (/-1,1,0/)    ! real(8) values\n  ! Answer Im getting: unknow = (/0,0,0/)  ! real(8) values\n\n\nend program lapackT\n</code></pre>\n', NULL, NULL, NULL, '2016-04-28', '2016-04-28'),
('["iteration","linear-algebra","sparse-matrix","matrix-inverse"]', '0', 19, 0, -1, 1461373374, 1461373374, 36805426, 'http://stackoverflow.com/questions/36805426/inverse-of-ab-when-a-is-fixed-and-b-is-changed-iteratively', 'Inverse of A+B when A is fixed and B is changed iteratively', '<p>I tried to solve </p>\n\n<p>(A+B(t))x=b(t)</p>\n\n<p>Here, A is time independent but B and b depends on time.</p>\n\n<p>A is stiffness matrix and B is mass matrix.</p>\n\n<p>Analytically, A+B(t) is symmetric positive definite and A and B(t) are both symmetric  positive definite. </p>\n\n<p>Structure of A is banded, but not block diagonal. B is block diagonal. Both are sparse matrix.</p>\n\n<p>In my code, I just solve (A+B(t))x=b(t). However, since A is fixed (which is hard to invert) and B varies on time (which is easy to invert), I think that this is very inefficient.</p>\n\n<p>Is there any other way to solve this problem whithout solve (A+B(t))x=b(t) at every t, but using that A is fixed?</p>\n', NULL, NULL, NULL, '2016-04-28', '2016-04-28'),
('["c++","linear-algebra","sparse-matrix","armadillo"]', '0', 19, 0, 0, 1461423818, 1461423818, 36812449, 'http://stackoverflow.com/questions/36812449/kronecker-product-in-armadillo', 'Kronecker Product in Armadillo', '<p>Is there a direct implementation of the Kronecker product of two sparse matrices using the armadillo library?</p>\n\n<p>The usual function:</p>\n\n<pre><code>   kron()\n</code></pre>\n\n<p>Does not seem to work, and I can''t seem to find any reference to an implementation.</p>\n\n<p>My thanks in advance.</p>\n', NULL, NULL, NULL, '2016-04-28', '2016-04-28'),
('["geometry","linear-algebra","lapack","scalapack","lapacke"]', '0', 18, 0, 0, 1461564908, 1461564908, 36833230, 'http://stackoverflow.com/questions/36833230/lapack-solving-large-periodic-banded-system-of-equations', 'LAPACK: Solving large periodic banded system of equations', '<p>I have to solve a large number of simultaneous equations (~1000s) to solve at every time step for a general mean curvature flow problem. The problem is defined over closed manifolds so the boundary condition is periodic.</p>\n\n<p>I am using successive-over-relaxation algorithm right now to solve this, but is very slow. I tried <code>dgbtrf -&gt; dgbtrs</code> (without the periodicity condition), and is quite faster.</p>\n\n<p>The coefficient matrix looks like this</p>\n\n<pre><code>     ⎛c₁   d₁ e₁        a₁   b₁⎞     ^\n     ⎢b₂   c₂ d₂ e₂  0       a₂⎥     |\n     ⎢a₃   b₃ c₃ d₃  .  0      ⎥     |\n A ← ⎢     a₄ b₄ c₄  .  .      ⎥   ~1000\n     ⎢      0  .  .  .  .  en₋₂⎥     |\n     ⎢en₋₁     0  .  .  .  dn₋₁⎥     |\n     ⎝dn   en        an bn  cn ⎠     v\n</code></pre>\n\n<p>I need to solve pentadiagonal systems, that are not symmetric and not known to be positive definite.</p>\n\n<p>Is there a way to solve cyclic/periodic banded systems in LAPACK?</p>\n\n<p>Or do I have to use general solvers, such as <code>dgetrs</code>?</p>\n', NULL, NULL, NULL, '2016-04-28', '2016-04-28'),
('["python","numpy","linear-algebra"]', '1', 32, 2, 3, 1461727798, 1461724807, 36879311, 'http://stackoverflow.com/questions/36879311/combine-einsum-expresions', 'Combine Einsum Expresions', '<p>I would like to evaluate </p>\n\n<pre><code>E = np.einsum(''ij,jk,kl-&gt;ijkl'',A,A,A)\nF = np.einsum(''ijki-&gt;ijk'',E)\n</code></pre>\n\n<p>where A is a matrix (no more than 1000 by 1000 in size). Computing E is slow. I would like to speed this up by only computing the "diagonal" elements which I store in F. Is it possible to combine these two expressions?/Are there any better ways to speed up this computation?</p>\n', NULL, NULL, NULL, '2016-04-28', '2016-04-28'),
('["matlab","random","statistics","linear-algebra","finance"]', '0', 19, 0, 0, 1461739980, 1461737673, 36881709, 'http://stackoverflow.com/questions/36881709/what-shape-should-we-get-by-plotting-the-log-log-graph-of-inverse-participation', 'What shape should we get by plotting the log-log graph of Inverse Participation Ratio of eigenvectors vs Eigenvalues for a random matrix?', '<p>The Inverse Participation Ratio (I.P.R.) of a vector u = (u1, .... um) for i =\n1, ..., m is defined as follows:</p>\n\n<p><a href="http://i.stack.imgur.com/li74x.png" rel="nofollow"><img src="http://i.stack.imgur.com/li74x.png" alt="enter image description here"></a></p>\n\n<p>When plotting the log-log of IPR of the eigenvectors vs the eigenvalues, L, we should get something interesting, perhaps a straight line like:</p>\n\n<p><a href="http://i.stack.imgur.com/i7me0.png" rel="nofollow"><img src="http://i.stack.imgur.com/i7me0.png" alt="enter image description here"></a></p>\n\n<p>But I am getting a haphazard thing:</p>\n\n<p><a href="http://i.stack.imgur.com/vGBHB.png" rel="nofollow"><img src="http://i.stack.imgur.com/vGBHB.png" alt="enter image description here"></a></p>\n\n<p>This is my code. </p>\n\n<pre><code>m=98; n=753;\nH=randn(m,n);\nW=1/n*(H*(H''));\n[U, lambda] = eig(W);\n\nfor i=1:size(U,2)\n    IPR(i,1)=0;\n    for j=1:98\n        IPR(i,1)=IPR(i,1)+U(j,i)^4;\n    end\n    L(i,1)=lambda(i,i);\nend\n\nloglog(L,IPR);\n</code></pre>\n\n<p>Could anyone please point out what I am doing wrong?</p>\n', NULL, NULL, NULL, '2016-04-28', '2016-04-28'),
('["c++","algorithm","boost","linear-algebra","numerical-analysis"]', '1', 11, 1, 1, 1461799066, 1461798073, 36902407, 'http://stackoverflow.com/questions/36902407/c-back-substitution-via-boost-bad-index-error', 'C++ - Back Substitution via Boost - Bad Index Error', '<p>I have the following code for a back substitution algorithm: </p>\n\n<pre><code>#include &lt;boost\\numeric\\ublas\\matrix.hpp&gt;\ntypedef boost::numeric::ublas::matrix&lt;double&gt; dM;\ndM bSub(dM A, dM b)\n{\n    unsigned int n = (int)b.size1();\n    assert(b.size2() == 1);\n    assert(n == A.size1());\n    dM x(n, 1);\n    for (unsigned i = (n - 1); i &gt;= 0; --i)\n    {\n        double sum = 0.0;\n        for (unsigned j = (n - 1); j &gt; i; --j)\n        {\n            sum += A(i, j)*x(j, 0);\n        }\n        x(i, 0) = (b(i, 0) - sum) / A(i, i);\n    }\n\n    return x;\n}\n</code></pre>\n\n<p>A bad index error pops up when I try to run it. I am not quite sure where the error is as I can''t find the problem when I am manually going through the algo.</p>\n\n<p>I have also tried incrementing the nested loop: <code>for(unsigned j = 0; j &lt; n; ++j)</code>. Again, I run into the same bad index error.</p>\n\n<p>Based on the debugger, I think the problem has to do with <code>i</code> somehow taking on a value of 4294967295, I am not sure where that number could come from as it doesn''t really fit in other parts of my code.  </p>\n\n<p>Lastly, I have also written a forward substitution algo, using a very similar structure, which runs without a problem.</p>\n\n<p>Anyone have an idea what''s going on?</p>\n', NULL, NULL, NULL, '2016-04-28', '2016-04-28');

/*!40101 SET CHARACTER_SET_CLIENT=@OLD_CHARACTER_SET_CLIENT */;
/*!40101 SET CHARACTER_SET_RESULTS=@OLD_CHARACTER_SET_RESULTS */;
/*!40101 SET COLLATION_CONNECTION=@OLD_COLLATION_CONNECTION */;
